# app.py â”€â”€ Streamlit (https://<YOUR-APP>.streamlit.app)

import io
from pathlib import Path
from datetime import date, timedelta
from pandas.io.formats.style import Styler

import pandas as pd
import numpy as np
import streamlit as st
import plotly.graph_objects as go
import re


# âœ… Ag-Grid (í•©ê³„í–‰ ìƒë‹¨ ê³ ì • & ì»¬ëŸ¼ í•„í„°/ì •ë ¬/ì„ íƒ ì§€ì›) â”€â”€ (ì‚¬ìš© ì•ˆ í•´ë„ ë¨: ë°ì´í„° ë§¤íŠ¸ë¦­ìŠ¤ëŠ” st.data_editor ì‚¬ìš©)
try:
    from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, JsCode
except Exception as _e:
    AgGrid = None

# ================= ê¸°ë³¸ ì„¤ì • =================
st.set_page_config(page_title="ì™¸ë¶€ìš”ì¸ ê¸°ë°˜ ë¹…ë°ì´í„° ì² ë„ ìˆ˜ìš”ì˜ˆì¸¡ í”Œë«í¼", layout="wide")

# ======= ìƒë‹¨ íƒ€ì´í‹€ + ë‹¤í¬ëª¨ë“œ í† ê¸€ =======
title_col, theme_col = st.columns([1,0.18])
with title_col:
    st.title("ğŸ“ˆ ì™¸ë¶€ìš”ì¸ ê¸°ë°˜ ë¹…ë°ì´í„° ì² ë„ ìˆ˜ìš”ì˜ˆì¸¡ í”Œë«í¼")
with theme_col:
    DARK = st.checkbox("ğŸŒ™ ë‹¤í¬ ëª¨ë“œ", value=False)

# ---------- í…Œë§ˆ ìƒ‰ìƒ ë³€ìˆ˜ ----------
if DARK:
    BG        = "#0B1220"; SURFACE="#111827"; PANEL_BG="#0F172A"; BORDER="#1F2937"
    TEXT      = "#E5E7EB"; SUBTEXT="#9CA3AF"; SHADOW="rgba(0,0,0,0.35)"
    HILITE1   = "rgba(56,189,248,0.12)"; HILITE2="rgba(148,163,184,0.10)"
    CARD_BG   = "#111827"; CARD_BORDER="#374151"; PLOTLY_TEMPLATE="plotly_dark"
    SUM_BG    = "rgba(56,189,248,0.10)"
else:
    BG        = "#FFFFFF"; SURFACE="#FFFFFF"; PANEL_BG="#F8FAFC"; BORDER="#E5E7EB"
    TEXT      = "#111827"; SUBTEXT="#6B7280"; SHADOW="rgba(0,0,0,0.05)"
    HILITE1   = "rgba(30,144,255,0.08)"; HILITE2="rgba(100,116,139,0.06)"
    CARD_BG   = "#FFFFFF"; CARD_BORDER="#E5E7EB"; PLOTLY_TEMPLATE="plotly_white"
    SUM_BG    = "rgba(30,144,255,0.08)"

# ---- ê¸€ë¡œë²Œ ìŠ¤íƒ€ì¼ ----
st.markdown(
    f"""
    <style>
    html, body, .stApp {{ background: {BG}; color:{TEXT}; }}
    .panel {{
        border: 1px solid {BORDER};
        background: {PANEL_BG};
        border-radius: 12px;
        padding: 12px 14px;
        box-shadow: 0 4px 18px {SHADOW};
        margin-bottom: 12px;
    }}
    .lg-line   {{ height:2px; border-top: 4px solid #1f77b4; border-radius:2px; display:inline-block; width:22px; margin-right:6px; }}
    .lg-line-dash {{
        height:0; display:inline-block; width:22px; margin-right:6px; position:relative; top:2px;
        border-top: 0; background: repeating-linear-gradient(90deg, #1f77b4 0 6px, rgba(0,0,0,0) 6px 12px);
    }}
    .lg-bar    {{ background:#ff7f0e; display:inline-block; width:12px; height:12px; border-radius:2px; margin-right:6px; }}
    .lg-bar-f  {{ background:#ff7f0e; opacity:0.7; display:inline-block; width:12px; height:12px; border-radius:2px; margin-right:6px; }}
    .lg-text   {{ font-size: 13px; color:{TEXT}; vertical-align:middle; }}
    .legend-row {{ display:flex; gap:18px; align-items:center; flex-wrap:wrap; justify-content:flex-end; }}
    div[data-testid="stDataFrame"] div[role="grid"] {{ background: {SURFACE}; }}
    </style>
    """,
    unsafe_allow_html=True,
)

# ===== ê¸°ê°„ ì •ì˜ =====
ACT_START = pd.to_datetime("2020-08-01")
ACT_END   = pd.to_datetime("2025-08-31")  # âœ… ì‹¤ì  ì¢…ë£Œ
FCT_START = pd.to_datetime("2025-09-01")
FCT_END   = pd.to_datetime("2025-11-29")

# ================= íŒŒì¼ ë¡œë” =================
@st.cache_data(show_spinner=False)
def load_df_from_repo_csv(filename: str):
    path = Path(filename)
    if not path.exists():
        raise FileNotFoundError(f"'{filename}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    for enc in ("utf-8-sig", "cp949"):
        try:
            return pd.read_csv(path, encoding=enc)
        except Exception:
            continue
    return pd.read_csv(path)

# ================= íœ´ì¼ ë¡œë” =================
@st.cache_data(show_spinner=False)
def load_holidays_df() -> pd.DataFrame:
    try:
        df = load_df_from_repo_csv("holidays_rows.csv").copy()
    except FileNotFoundError:
        st.warning("'holidays_rows.csv' íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. íœ´ë¬´ í‘œì‹œëŠ” ìƒëµë©ë‹ˆë‹¤.")
        return pd.DataFrame(columns=["holiday_date","name"])
    if "holiday_date" not in df.columns:
        st.warning("'holidays_rows.csv'ì— 'holiday_date' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. íœ´ë¬´ í‘œì‹œëŠ” ìƒëµë©ë‹ˆë‹¤.")
        return pd.DataFrame(columns=["holiday_date","name"])
    if "name" not in df.columns:
        df["name"] = ""
    df["holiday_date"] = pd.to_datetime(df["holiday_date"], errors="coerce").dt.normalize()
    df = df.dropna(subset=["holiday_date"]).drop_duplicates(subset=["holiday_date"]).sort_values("holiday_date")
    return df[["holiday_date","name"]]

# ================= ì‹¤ì  / ì˜ˆì¸¡ ë¡œë” =================
@st.cache_data(show_spinner=False)
def load_actual_df() -> pd.DataFrame:
    df = load_df_from_repo_csv("merged.csv").copy()
    cols = {c.lower(): c for c in df.columns}
    df.rename(columns={cols.get("date","date"):"date",
                       cols.get("passengers","passengers"):"passengers",
                       cols.get("sales_amount","sales_amount"):"sales_amount"}, inplace=True)
    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    df = df.dropna(subset=["date"]).sort_values("date")
    df = df[(df["date"] >= ACT_START) & (df["date"] <= ACT_END)]
    df["passengers"] = pd.to_numeric(df["passengers"], errors="coerce")
    df["sales_amount"] = pd.to_numeric(df["sales_amount"], errors="coerce")
    return df

@st.cache_data(show_spinner=False)
def load_forecast_df() -> pd.DataFrame:
    f = load_df_from_repo_csv("forecast_pass.csv").copy()
    cols = {c.lower(): c for c in f.columns}
    f.rename(columns={cols.get("date","date"):"date",
                      cols.get("forecast_90d","forecast_90d"):"passengers"}, inplace=True)
    f["date"] = pd.to_datetime(f["date"], errors="coerce")
    f = f.dropna(subset=["date"]).sort_values("date")
    f = f[(f["date"] >= FCT_START) & (f["date"] <= FCT_END)]
    f["passengers"] = pd.to_numeric(f["passengers"], errors="coerce")
    f["sales_amount"] = np.nan
    return f

@st.cache_data(show_spinner=False)
def load_forecast_sales_df() -> pd.DataFrame:
    f = load_df_from_repo_csv("forecast_sales.csv").copy()
    cols = {c.lower(): c for c in f.columns}
    f.rename(columns={cols.get("date","date"):"date",
                      cols.get("forecast_90d","forecast_90d"):"pred_sales_amount"}, inplace=True)
    f["date"] = pd.to_datetime(f["date"], errors="coerce")
    f = f.dropna(subset=["date"]).sort_values("date")
    f = f[(f["date"] >= FCT_START) & (f["date"] <= FCT_END)]
    f["pred_sales_amount"] = pd.to_numeric(f["pred_sales_amount"], errors="coerce")
    return f[["date","pred_sales_amount"]]

@st.cache_data(show_spinner=False)
def load_actual_rows_df() -> pd.DataFrame:
    df = load_df_from_repo_csv("train_reservations_rows.csv").copy()
    required = ["travel_date","passengers","sales_amount"]
    miss = [c for c in required if c not in df.columns]
    if miss: raise KeyError(f"'train_reservations_rows.csv'ì— ë‹¤ìŒ ì»¬ëŸ¼ í•„ìš”: {', '.join(miss)}")
    df["travel_date"] = pd.to_datetime(df["travel_date"], errors="coerce")
    df = df.dropna(subset=["travel_date"])
    for c in ["passengers","sales_amount"]:
        df[c] = df[c].astype(str).str.replace(",", "", regex=False).replace("nan", np.nan)
        df[c] = pd.to_numeric(df[c], errors="coerce")
    daily = (df.assign(date=df["travel_date"].dt.floor("D"))
               .groupby("date", as_index=False)[["passengers","sales_amount"]].sum()
               .sort_values("date"))
    daily = daily[(daily["date"] >= ACT_START) & (daily["date"] <= ACT_END)]
    return daily

# ================= ìœ í‹¸ =================
KO_DAYS = ["ì›”","í™”","ìˆ˜","ëª©","ê¸ˆ","í† ","ì¼"]
def fmt_date_ko(s: pd.Series) -> pd.Series:
    return s.dt.strftime("%Y-%m-%d") + " (" + s.dt.weekday.map(dict(enumerate(KO_DAYS))) + ")"

def ensure_in_range(s: pd.Timestamp, e: pd.Timestamp, lo: pd.Timestamp, hi: pd.Timestamp):
    s2 = max(s, lo); e2 = min(e, hi)
    if s2 > e2: s2, e2 = lo, lo
    return s2, e2

def align_last_year_same_weekday(r_s: pd.Timestamp, n_days: int):
    raw = (r_s - pd.DateOffset(years=1)).normalize()
    diff = (r_s.weekday() - raw.weekday()) % 7
    l_s = raw + pd.Timedelta(days=diff)
    l_e = l_s + pd.Timedelta(days=n_days-1)
    l_s, l_e = ensure_in_range(l_s, l_e, ACT_START, ACT_END)
    cur = (l_e - l_s).days + 1
    if cur < n_days:
        deficit = n_days - cur
        l_s = max(ACT_START, l_s - pd.Timedelta(days=deficit))
        l_e = l_s + pd.Timedelta(days=n_days-1)
    return ensure_in_range(l_s, l_e, ACT_START, ACT_END)

def force_same_length(left_s, left_e, right_s, right_e):
    n = (right_e - right_s).days + 1
    left_e_target = left_s + pd.Timedelta(days=n-1)
    left_s2, left_e2 = ensure_in_range(left_s, left_e_target, ACT_START, ACT_END)
    cur = (left_e2 - left_s2).days + 1
    if cur < n:
        deficit = n - cur
        left_s2 = max(ACT_START, left_s2 - pd.Timedelta(days=deficit))
    left_s2, left_e2 = ensure_in_range(left_s2, left_s2 + pd.Timedelta(days=n-1), ACT_START, ACT_END)
    right_s2, right_e2 = ensure_in_range(right_s, right_e, FCT_START, FCT_END)
    return left_s2, left_e2, right_s2, right_e2

# --------- ì™¸ë¶€ìš”ì¸(ì´ë²¤íŠ¸ í•©ê³„) + íœ´ì¼ í”Œë˜ê·¸ ----------
@st.cache_data(show_spinner=False)
def load_external_factors_df() -> pd.DataFrame:
    try:
        df = load_df_from_repo_csv("merged.csv").copy()
    except FileNotFoundError:
        st.warning("'merged.csv' íŒŒì¼ì„ ì°¾ì§€ ëª»í•´ ì´ë²¤íŠ¸ í•©ê³„ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(columns=["date","event_sum"])
    df.columns = [str(c).strip().lower() for c in df.columns]
    if "date" not in df.columns:
        st.warning("'merged.csv'ì— 'date' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(columns=["date","event_sum"])
    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    df = df.dropna(subset=["date"]).sort_values("date")
    event_cols = ["bexco_events_count","coex_events_count","kintex_events_count",
                  "games_baseball","games_soccer","concerts_events_count"]
    for c in event_cols:
        if c not in df.columns: df[c] = 0
        df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0)
    df["event_sum"] = df[event_cols].sum(axis=1)
    df = df[(df["date"] >= ACT_START) & (df["date"] <= ACT_END)]
    return df[["date","event_sum"]]

def build_event_strings(dates_index: pd.DatetimeIndex, factors_df: pd.DataFrame) -> list[str]:
    if dates_index is None or len(dates_index) == 0: return []
    if isinstance(factors_df, pd.DataFrame) and not factors_df.empty and "date" in factors_df.columns:
        f = factors_df.set_index("date").reindex(dates_index)
        ev = pd.to_numeric(f.get("event_sum"), errors="coerce").fillna(0)
    else:
        ev = pd.Series([0]*len(dates_index), index=dates_index)
    return [f"ì´ë²¤íŠ¸ {int(round(v))}" for v in ev]

# === íœ´ì¼ëª… 6ì ë¼ë²¨ + íˆ´íŒ ì „ì²´ëª… ===
def _truncate_with_ellipsis(text: str, max_len: int = 6) -> str:
    if not isinstance(text, str):
        return ""
    return text if len(text) <= max_len else (text[:max_len] + "â€¦")

def build_holiday_labels(dates_index: pd.DatetimeIndex, holidays_df: pd.DataFrame, max_len: int = 6):
    if dates_index is None or len(dates_index) == 0:
        return [], []
    if holidays_df is None or holidays_df.empty or "holiday_date" not in holidays_df.columns:
        return ["" for _ in range(len(dates_index))], ["" for _ in range(len(dates_index))]
    hmap = holidays_df.set_index("holiday_date")["name"]
    labels, fulls = [], []
    for d in dates_index:
        name = hmap.get(d.normalize(), "")
        if isinstance(name, float) and np.isnan(name):
            name = ""
        if name:
            labels.append(_truncate_with_ellipsis(str(name), max_len))
            fulls.append(str(name))
        else:
            labels.append("")
            fulls.append("")
    return labels, fulls

import streamlit as st

def set_sidebar_font(size_px: int = 16, label_px: int | None = None, line_height: float = 1.35):
    """
    Streamlit ì‚¬ì´ë“œë°” í°íŠ¸ í¬ê¸°/ì¤„ê°„ê²©ì„ CSSë¡œ ì¼ê´„ ì¡°ì •í•©ë‹ˆë‹¤.
    - size_px: ì‚¬ì´ë“œë°” ê¸°ë³¸ í°íŠ¸ í¬ê¸°(px)
    - label_px: ìœ„ì ¯ ë¼ë²¨(ì˜ˆ: radio, date_input ë¼ë²¨) í¬ê¸°(px). Noneì´ë©´ size_px ì‚¬ìš©
    - line_height: ì¤„ê°„ê²©
    """
    if label_px is None:
        label_px = size_px
    st.markdown(
        f"""
        <style>
        /* ì‚¬ì´ë“œë°” ì˜ì—­ ì „ì²´ */
        [data-testid="stSidebar"] * {{
            font-size: {size_px}px !important;
            line-height: {line_height} !important;
        }}
        /* ì„¹ì…˜ í—¤ë”/ì„œë¸Œí—¤ë”(í¬ê²Œ ë³´ì´ê²Œ ì•½ê°„ ì¦í­) */
        [data-testid="stSidebar"] h1,
        [data-testid="stSidebar"] h2,
        [data-testid="stSidebar"] h3 {{
            font-size: {int(size_px*1.15)}px !important;
            font-weight: 700 !important;
        }}
        /* ìœ„ì ¯ ë¼ë²¨(ì˜ˆ: radio, date_input ë ˆì´ë¸”) */
        [data-testid="stSidebar"] label,
        [data-testid="stWidgetLabel"] p,
        [data-testid="stWidgetLabel"] label {{
            font-size: {label_px}px !important;
            font-weight: 600 !important;
        }}
        /* date_input í•„ë“œ ë‚´ë¶€ ê¸€ì */
        [data-testid="stSidebar"] [data-testid="stDateInput"] input {{
            font-size: {size_px}px !important;
        }}
        /* radio í•­ëª© ë¼ë²¨ */
        [data-testid="stSidebar"] [data-testid="stRadio"] label p {{
            font-size: {size_px}px !important;
        }}
        /* êµ¬ë¶„ì„  ì—¬ë°± ì‚´ì§ ë„‰ë„‰í•˜ê²Œ */
        [data-testid="stSidebar"] hr {{
            margin: 0.6rem 0 !important;
        }}
        </style>
        """,
        unsafe_allow_html=True,
    )

import streamlit as st

def set_sidebar_style(font_size=16, line_height=1.6, paragraph_gap="0.8rem"):
    """
    Streamlit ì‚¬ì´ë“œë°” í°íŠ¸ ë° ë¬¸ë‹¨ ê°„ê²© ìŠ¤íƒ€ì¼ ì„¤ì •
    - font_size: ê¸°ë³¸ í°íŠ¸ í¬ê¸°(px)
    - line_height: ì¤„ ê°„ê²©(line-height)
    - paragraph_gap: ë¬¸ë‹¨(p, div ë“±) ì‚¬ì´ ì—¬ë°± (rem ë˜ëŠ” px)
    """
    st.markdown(
        f"""
        <style>
        [data-testid="stSidebar"] * {{
            font-size: {font_size}px !important;
            line-height: {line_height} !important;
        }}
        /* ë¬¸ë‹¨ ê°„ ê°„ê²© */
        [data-testid="stSidebar"] p,
        [data-testid="stSidebar"] div,
        [data-testid="stSidebar"] label {{
            margin-bottom: {paragraph_gap} !important;
        }}
        /* ìœ„ì ¯ ê°„ ì—¬ë°±ë„ ë„‰ë„‰í•˜ê²Œ */
        [data-testid="stSidebar"] .stRadio,
        [data-testid="stSidebar"] .stDateInput,
        [data-testid="stSidebar"] .stSelectbox {{
            margin-bottom: {paragraph_gap} !important;
        }}
        /* êµ¬ë¶„ì„ (hr) ìƒí•˜ ì—¬ë°± */
        [data-testid="stSidebar"] hr {{
            margin: 1rem 0 !important;
        }}
        </style>
        """,
        unsafe_allow_html=True
    )


# ===================== ìŠ¤íƒ€ì¼: ì‚¬ì´ë“œë°” í°íŠ¸ =====================
set_sidebar_font(size_px=20, label_px=18, line_height=1.4)

# ===================== ì‚¬ì´ë“œë°”: ê¸°ê°„ ì„ íƒ =====================
# ===== ìŠ¤íƒ€ì¼ ì„¤ì • =====
set_sidebar_style(font_size=17, line_height=1.6, paragraph_gap="0.6rem")

# ===== ì‚¬ì´ë“œë°” ì˜ˆì‹œ =====
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“… ê¸°ê°„ ì„ íƒ")

default_right_start = date(2025, 9, 1)
default_right_end   = date(2025, 9, 7)
right_range = st.session_state.get("right_range", (default_right_start, default_right_end))
right_sel = st.sidebar.date_input(
    "â‘  ì˜ˆì¸¡ ê¸°ê°„ (YYYY-MM-DD)",
    value=right_range, min_value=FCT_START.date(), max_value=FCT_END.date(), key="right_picker_sidebar"
)

# â”€â”€ (êµì²´) ì‹¤ì  ê¸°ê°„ ëª¨ë“œ: ê°€ë¡œ ë¼ë””ì˜¤, (O) ëŠë‚Œ
mode_options = ["ì‚¬ìš© ì•ˆí•¨ (ì˜ˆì¸¡ë§Œ)", "ì „ë…„ë„ ë™ì¼(ì¼ì)", "ì „ë…„ë„ ë™ì¼(ìš”ì¼)", "ì‚¬ìš©ì ì§€ì •"]
st.sidebar.markdown(
    """
    <style>
    /* ì‚¬ì´ë“œë°” ë¼ë””ì˜¤ë¥¼ ê°€ë¡œë¡œ ë³´ê¸° ì¢‹ê²Œ */
    [data-testid="stSidebar"] [role="radiogroup"] { gap: 10px !important; }
    [data-testid="stSidebar"] [data-baseweb="radio"] { margin-right: 8px !important; }
    [data-testid="stSidebar"] [data-baseweb="radio"] label p { font-weight: 600 !important; }
    </style>
    """, unsafe_allow_html=True
)
left_mode = st.sidebar.radio(
    "â‘¡ ì‹¤ì  ê¸°ê°„ ëª¨ë“œ",
    options=mode_options,
    index=1,
    key="left_mode_sidebar",
    horizontal=True,  # â† ê°€ë¡œ ë°°ì¹˜
)


if left_mode == "ì‚¬ìš©ì ì§€ì •":
    left_range = st.session_state.get("left_range", (date(2024, 9, 1), date(2024, 9, 7)))
    left_sel = st.sidebar.date_input(
        "ì‹¤ì  ê¸°ê°„ (YYYY-MM-DD)",
        value=left_range, min_value=ACT_START.date(), max_value=ACT_END.date(), key="left_picker_sidebar"
    )


# ================= ê¸°ê°„ ì •ê·œí™”/ë™ê¸°í™” =================
def norm_tuple(sel):
    return sel if isinstance(sel, tuple) else (sel, sel)

r_s, r_e = map(pd.to_datetime, norm_tuple(right_sel))
r_s, r_e = ensure_in_range(r_s, r_e, FCT_START, FCT_END)
N_days = (r_e - r_s).days + 1

if left_mode == "ì‚¬ìš© ì•ˆí•¨ (ì˜ˆì¸¡ë§Œ)":
    l_s, l_e = None, None
elif left_mode == "ì „ë…„ë„ ë™ì¼(ì¼ì)":
    l_s = (r_s - pd.DateOffset(years=1)).normalize(); l_e = l_s + pd.Timedelta(days=N_days-1)
    l_s, l_e = ensure_in_range(l_s, l_e, ACT_START, ACT_END)
elif left_mode == "ì „ë…„ë„ ë™ì¼(ìš”ì¼)":
    l_s, l_e = align_last_year_same_weekday(r_s, N_days)
else:
    l_s, l_e = map(pd.to_datetime, norm_tuple(left_sel))
    l_s, l_e, r_s, r_e = force_same_length(l_s, l_e, r_s, r_e)

st.session_state["right_range"] = (r_s.date(), r_e.date())
if left_mode == "ì‚¬ìš©ì ì§€ì •" and l_s is not None:
    st.session_state["left_range"] = (l_s.date(), l_e.date())

# ================= ì™¸ë¶€ ë°ì´í„° ë¡œë“œ =================
actual_df_all   = load_actual_df()
forecast_df_all = load_forecast_df()
external_factors_df = load_external_factors_df()
holidays_df = load_holidays_df()

try:
    forecast_sales_all = load_forecast_sales_df()
except FileNotFoundError as e:
    st.warning(f"ì˜ˆì¸¡ ë§¤ì¶œ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")
    forecast_sales_all = pd.DataFrame(columns=["date","pred_sales_amount"])

def get_range(df, s, e, tag):
    if s is None or e is None: return pd.DataFrame(columns=["date","passengers","sales_amount","source"])
    out = df[(df["date"] >= s) & (df["date"] <= e)].copy(); out["source"] = tag; return out

left_df  = get_range(actual_df_all,   l_s, l_e, "actual") if l_s is not None else pd.DataFrame(columns=["date","passengers","sales_amount","source"])
right_df = get_range(forecast_df_all, r_s, r_e, "forecast")

if not right_df.empty:
    right_df = right_df.merge(forecast_sales_all, on="date", how="left")
    right_df["sales_amount"] = np.where(right_df["sales_amount"].isna(), right_df["pred_sales_amount"], right_df["sales_amount"])

df_sel = pd.concat(
    ([left_df.assign(period="ì‹¤ì ê¸°ê°„")] if not left_df.empty else []) + [right_df.assign(period="ì˜ˆì¸¡ê¸°ê°„")],
    ignore_index=True).sort_values("date") if (not right_df.empty or not left_df.empty) else pd.DataFrame(columns=["date","passengers","sales_amount","source","period"])

df_sel["sales_million"] = pd.to_numeric(df_sel["sales_amount"], errors="coerce")/1_000_000
df_sel["passengers_k"]  = pd.to_numeric(df_sel["passengers"], errors="coerce")/1_000

# ================= Xì¶• ì¹´í…Œê³ ë¦¬ =================
order_left  = pd.date_range(l_s, l_e, freq="D") if l_s is not None else pd.DatetimeIndex([])
order_right = pd.date_range(r_s, r_e, freq="D")
category_array = (
    [f"ì‹¤ì |{d.strftime('%Y-%m-%d')}" for d in order_left] +
    [f"ì˜ˆì¸¡|{d.strftime('%Y-%m-%d')}" for d in order_right]
)
if not df_sel.empty:
    df_sel["x_cat"] = df_sel.apply(lambda r: f"{'ì‹¤ì ' if r['period']=='ì‹¤ì ê¸°ê°„' else 'ì˜ˆì¸¡'}|{r['date'].strftime('%Y-%m-%d')}", axis=1)

# =================== ê·¸ë˜í”„ íŒ¨ë„(ë¶„ë¦¬) ===================
st.markdown('<div class="panel">', unsafe_allow_html=True)
st.subheader("ğŸ“Šê·¸ë˜í”„")

sp, cSales, cPax = st.columns([8,1.6,1.6])
with cSales: show_sales = st.checkbox("ë§¤ì¶œì•¡", True, key="cb_sales")
with cPax:   show_pax   = st.checkbox("ìŠ¹ê°ìˆ˜", True, key="cb_pax")

def _add_watermark(fig, text: str):
    # íˆ¬ëª…ë„ ìˆëŠ” ì›Œí„°ë§ˆí¬ (ë ˆì´ì–´: below)
    fig.add_annotation(
        x=0.5, y=0.5, xref="paper", yref="paper",
        text=text, showarrow=False,
        font=dict(size=48, color="rgba(0,0,0,0.08)"),
        align="center", opacity=1.0
    )
    # ë°°ê²½/í”Œë¡¯ ìƒ‰ìƒ ì¼ì¹˜ & ê·¸ë¦¬ë“œ ë³´ì´ë˜ ì€ì€í•˜ê²Œ
    fig.update_layout(
        template=PLOTLY_TEMPLATE,
        paper_bgcolor=PANEL_BG, plot_bgcolor=PANEL_BG,
        xaxis=dict(showgrid=True), yaxis=dict(showgrid=True),
        margin=dict(t=24, r=30, b=60, l=70),
        showlegend=False,
        font=dict(family="Nanum Gothic, Malgun Gothic, AppleGothic, Noto Sans KR, Sans-Serif", size=13, color=TEXT),
    )

def _build_single_fig(df: pd.DataFrame, title_text: str):
    fig = go.Figure()
    if df.empty:
        _add_watermark(fig, title_text)
        return fig

    # ìŠ¹ê°ìˆ˜(ë§‰ëŒ€, y2)
    if show_pax and ("passengers_k" in df.columns):
        fig.add_trace(go.Bar(
            x=df["date"], y=df["passengers_k"], name="ìŠ¹ê°ìˆ˜",
            marker=dict(line=dict(width=0)),
            opacity=0.55, yaxis="y2",
            hovertemplate="<b>%{x|%Y-%m-%d}</b><br>ìŠ¹ê°ìˆ˜: %{y:,.0f} ì²œëª…<extra></extra>"
        ))
    # ë§¤ì¶œ(ì„ , y1)
    if show_sales and ("sales_million" in df.columns):
        fig.add_trace(go.Scatter(
            x=df["date"], y=df["sales_million"], name="ë§¤ì¶œì•¡", mode="lines+markers",
            line=dict(width=2.6), marker=dict(size=6),
            yaxis="y1", connectgaps=True,
            hovertemplate="<b>%{x|%Y-%m-%d}</b><br>ë§¤ì¶œì•¡: %{y:,.0f} ë°±ë§Œì›<extra></extra>"
        ))

    # ë“€ì–¼ì¶•
    fig.update_layout(
        xaxis=dict(title="", type="date", tickformat="%Y-%m-%d", tickangle=-45),
        yaxis=dict(title="ë§¤ì¶œì•¡(ë°±ë§Œì›)", tickformat=",.0f"),
        yaxis2=dict(title="ìŠ¹ê°ìˆ˜(ì²œëª…)", overlaying="y", side="right", tickformat=",.0f"),
        barmode="group", bargap=0.15, bargroupgap=0.05,
    )

    _add_watermark(fig, title_text)
    return fig

# ì™¼ìª½/ì˜¤ë¥¸ìª½ ë°ì´í„° ì¤€ë¹„
left_plot_df  = pd.DataFrame()
right_plot_df = pd.DataFrame()
if not left_df.empty:
    left_plot_df = left_df.copy()
    left_plot_df["sales_million"] = pd.to_numeric(left_plot_df["sales_amount"], errors="coerce")/1_000_000
    left_plot_df["passengers_k"]  = pd.to_numeric(left_plot_df["passengers"],   errors="coerce")/1_000
if not right_df.empty:
    right_plot_df = right_df.copy()
    right_plot_df["sales_million"] = pd.to_numeric(right_plot_df["sales_amount"], errors="coerce")/1_000_000
    right_plot_df["passengers_k"]  = pd.to_numeric(right_plot_df["passengers"],   errors="coerce")/1_000

# ë ˆì´ì•„ì›ƒ: ì‹¤ì ì´ ì—†ìœ¼ë©´ ì˜ˆì¸¡ì´ ì „í­ ì‚¬ìš©
if left_plot_df.empty:
    fig_right = _build_single_fig(right_plot_df, "ì˜ˆì¸¡")
    st.plotly_chart(
        fig_right, use_container_width=True,
        config=dict(displaylogo=False,
                    toImageButtonOptions=dict(format="png", filename=f"forecast_{date.today()}", scale=2),
                    modeBarButtonsToAdd=["hovercompare"])
    )
else:
    colL, colR = st.columns(2)
    with colL:
        st.markdown("**âœ…ì‹¤ì **")
        fig_left = _build_single_fig(left_plot_df, "ì‹¤ì ")
        st.plotly_chart(
            fig_left, use_container_width=True,
            config=dict(displaylogo=False,
                        toImageButtonOptions=dict(format="png", filename=f"actual_{date.today()}", scale=2),
                        modeBarButtonsToAdd=["hovercompare"])
        )
    with colR:
        st.markdown("**âœ…ì˜ˆì¸¡**")
        fig_right = _build_single_fig(right_plot_df, "ì˜ˆì¸¡")
        st.plotly_chart(
            fig_right, use_container_width=True,
            config=dict(displaylogo=False,
                        toImageButtonOptions=dict(format="png", filename=f"forecast_{date.today()}", scale=2),
                        modeBarButtonsToAdd=["hovercompare"])
        )

st.markdown('</div>', unsafe_allow_html=True)

# ===================== í‘œ(ì‹¤ì /ì˜ˆì¸¡) =====================
left_dates  = pd.date_range(l_s, l_e, freq="D") if l_s is not None else pd.DatetimeIndex([])
right_dates = pd.date_range(r_s, r_e, freq="D")

left_tbl  = pd.DataFrame({"pos": range(len(left_dates)), "date": left_dates}) if len(left_dates)>0 else pd.DataFrame(columns=["pos","date"])
right_tbl = pd.DataFrame({"pos": range(len(right_dates)),"date": right_dates})

# ì™¸ë¶€ìš”ì¸: ì‹¤ì (ì´ë²¤íŠ¸/íœ´ë¬´ì—¬ë¶€ ë¶„ë¦¬), ì˜ˆì¸¡(íœ´ë¬´ì—¬ë¶€)
left_event_strings  = build_event_strings(left_dates, external_factors_df) if len(left_dates)>0 else []

if not left_df.empty:
    l_vals = left_df.set_index("date").reindex(left_dates)
    left_tbl["sales_million"] = (pd.to_numeric(l_vals["sales_amount"], errors="coerce")/1_000_000).values
    left_tbl["passengers_k"]  = (pd.to_numeric(l_vals["passengers"],   errors="coerce")/1_000).values
r_vals = right_df.set_index("date").reindex(right_dates) if not right_df.empty else pd.DataFrame(index=right_dates)
right_tbl["sales_million"] = (pd.to_numeric(r_vals.get("sales_amount"), errors="coerce")/1_000_000).values
right_tbl["passengers_k"]  = (pd.to_numeric(r_vals.get("passengers"),   errors="coerce")/1_000).values

merged_tbl = pd.merge(
    right_tbl,
    left_tbl[["pos","sales_million","passengers_k"]] if not left_tbl.empty else pd.DataFrame(columns=["pos"]),
    on="pos", how="left", suffixes=("_f","_a")
)

for c in ["sales_million_f","sales_million_a","passengers_k_f","passengers_k_a"]:
    merged_tbl[c] = pd.to_numeric(merged_tbl.get(c), errors="coerce")

old_sales = merged_tbl["sales_million_a"]; new_sales = merged_tbl["sales_million_f"]
merged_tbl["sales_pct"] = np.where((old_sales.isna()) | (old_sales==0), np.nan, (new_sales-old_sales)/old_sales*100.0)
old_pax = merged_tbl["passengers_k_a"]; new_pax = merged_tbl["passengers_k_f"]
merged_tbl["pax_pct"] = np.where((old_pax.isna()) | (old_pax==0), np.nan, (new_pax-old_pax)/old_pax*100.0)

# === íœ´ì¼ ë¼ë²¨/íˆ´íŒ (ì‹¤ì /ì˜ˆì¸¡ ëª¨ë‘ ìƒì„±)
left_holiday_labels, left_holiday_fulls = ([], [])
right_holiday_labels, right_holiday_fulls = ([], [])
if len(left_dates) > 0:
    left_holiday_labels, left_holiday_fulls = build_holiday_labels(left_dates, holidays_df, max_len=6)
right_holiday_labels, right_holiday_fulls = build_holiday_labels(right_dates, holidays_df, max_len=6)

# ---- í‘œ ë°ì´í„° êµ¬ì„± ----
actual_df_show = pd.DataFrame()
if not left_tbl.empty:
    d = {
        "ì‹¤ì |ì¼ì": fmt_date_ko(left_tbl["date"]),
        "ì‹¤ì |ë§¤ì¶œì•¡(ë°±ë§Œì›)": left_tbl["sales_million"].round(0).astype("Int64") if st.session_state.get("cb_sales", True) else pd.NA,
        "ì‹¤ì |ìŠ¹ê°ìˆ˜(ì²œëª…)" : left_tbl["passengers_k"].round(0).astype("Int64") if st.session_state.get("cb_pax", True) else pd.NA,
        "ì‹¤ì |ì™¸ë¶€ìš”ì¸"     : left_event_strings,  # â† í´ë¦­ ëŒ€ìƒ (ì´ë²¤íŠ¸ N)
        "ì‹¤ì |íœ´ë¬´ì—¬ë¶€"     : left_holiday_labels,
        "ì‹¤ì |íœ´ì¼ëª…(í’€)"   : left_holiday_fulls,
    }
    actual_df_show = pd.DataFrame({k:v for k,v in d.items()
                                   if not (isinstance(v, pd.Series) and v.isna().all())})

fcast_dict = {
    "ì˜ˆì¸¡|ì¼ì": fmt_date_ko(right_tbl["date"]),
}
if st.session_state.get("cb_sales", True):
    fcast_dict["ì˜ˆì¸¡|ë§¤ì¶œì•¡(ë°±ë§Œì›(Î”))"] = [
        f"{int(round(v if not pd.isna(v) else 0)):,.0f}" + (f" ({'â–²' if (not pd.isna(p) and p>=0) else ('â–¼' if not pd.isna(p) else '')}{'' if pd.isna(p) else f'{abs(p):.1f}%'} )" if not pd.isna(p) else "")
        for v,p in zip(right_tbl["sales_million"], merged_tbl["sales_pct"])
    ]
if st.session_state.get("cb_pax", True):
    fcast_dict["ì˜ˆì¸¡|ìŠ¹ê°ìˆ˜(ì²œëª…(Î”))"] = [
        f"{int(round(v if not pd.isna(v) else 0)):,.0f}" + (f" ({'â–²' if (not pd.isna(p) and p>=0) else ('â–¼' if not pd.isna(p) else '')}{'' if pd.isna(p) else f'{abs(p):.1f}%'} )" if not pd.isna(p) else "")
        for v,p in zip(right_tbl["passengers_k"], merged_tbl["pax_pct"])
    ]
fcast_dict["ì˜ˆì¸¡|íœ´ë¬´ì—¬ë¶€"]   = right_holiday_labels
fcast_dict["ì˜ˆì¸¡|íœ´ì¼ëª…(í’€)"] = right_holiday_fulls

forecast_df_show = pd.DataFrame(fcast_dict)

# í•©ì¹˜ê¸°
if not actual_df_show.empty:
    table_df = pd.concat([actual_df_show, forecast_df_show], axis=1)
else:
    table_df = forecast_df_show.copy()

# í•©ê³„í–‰(ì²« í–‰)
left_sales_m   = int(round(left_tbl["sales_million"].sum())) if "sales_million" in left_tbl.columns else 0
left_pax_k     = int(round(left_tbl["passengers_k"].sum()))   if "passengers_k"  in left_tbl.columns else 0
right_sales_m2 = int(round(right_tbl["sales_million"].sum())) if "sales_million" in right_tbl.columns else 0
right_pax_k2   = int(round(right_tbl["passengers_k"].sum()))  if "passengers_k"  in right_tbl.columns else 0

def top_delta_str(val, base):
    if base is None or base == 0 or val is None: return ""
    delta = (val - base) / base * 100.0; arrow = "â–²" if delta >= 0 else "â–¼"
    return f" ({arrow}{abs(delta):.1f}%)"

sum_row = {}
# ì‹¤ì  í•©ê³„
if "ì‹¤ì |ì¼ì" in table_df.columns: sum_row["ì‹¤ì |ì¼ì"] = "í•©ê³„"
if "ì‹¤ì |ë§¤ì¶œì•¡(ë°±ë§Œì›)" in table_df.columns: sum_row["ì‹¤ì |ë§¤ì¶œì•¡(ë°±ë§Œì›)"] = left_sales_m
if "ì‹¤ì |ìŠ¹ê°ìˆ˜(ì²œëª…)"  in table_df.columns: sum_row["ì‹¤ì |ìŠ¹ê°ìˆ˜(ì²œëª…)"]  = left_pax_k
if "ì‹¤ì |ì™¸ë¶€ìš”ì¸"      in table_df.columns: sum_row["ì‹¤ì |ì™¸ë¶€ìš”ì¸"]      = ""
if "ì‹¤ì |íœ´ë¬´ì—¬ë¶€"      in table_df.columns: sum_row["ì‹¤ì |íœ´ë¬´ì—¬ë¶€"]      = ""
if "ì‹¤ì |íœ´ì¼ëª…(í’€)"    in table_df.columns: sum_row["ì‹¤ì |íœ´ì¼ëª…(í’€)"]    = ""
# ì˜ˆì¸¡ í•©ê³„
if "ì˜ˆì¸¡|ì¼ì" in table_df.columns: sum_row["ì˜ˆì¸¡|ì¼ì"] = "í•©ê³„"
if "ì˜ˆì¸¡|ë§¤ì¶œì•¡(ë°±ë§Œì›(Î”))" in table_df.columns:
    sum_row["ì˜ˆì¸¡|ë§¤ì¶œì•¡(ë°±ë§Œì›(Î”))"] = f"{right_sales_m2:,.0f}{top_delta_str(right_sales_m2, left_sales_m if left_sales_m>0 else None)}"
if "ì˜ˆì¸¡|ìŠ¹ê°ìˆ˜(ì²œëª…(Î”))" in table_df.columns:
    sum_row["ì˜ˆì¸¡|ìŠ¹ê°ìˆ˜(ì²œëª…(Î”))"]   = f"{right_pax_k2:,.0f}{top_delta_str(right_pax_k2, left_pax_k if left_pax_k>0 else None)}"
if "ì˜ˆì¸¡|íœ´ë¬´ì—¬ë¶€" in table_df.columns: sum_row["ì˜ˆì¸¡|íœ´ë¬´ì—¬ë¶€"] = ""
if "ì˜ˆì¸¡|íœ´ì¼ëª…(í’€)" in table_df.columns: sum_row["ì˜ˆì¸¡|íœ´ì¼ëª…(í’€)"] = ""

# ======== ë§¤íŠ¸ë¦­ìŠ¤ ë Œë”ë§ (ì‹¤ì /ì˜ˆì¸¡ ë¶„ë¦¬) ========
st.markdown("#### ğŸ“‹ ë°ì´í„° í‘œ")

# ---- ì‹¤ì /ì˜ˆì¸¡ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± í•¨ìˆ˜ (ë™ì¼)
def _build_left_matrix() -> pd.DataFrame:
    if left_tbl.empty:
        return pd.DataFrame()
    rows = {}
    if st.session_state.get("cb_sales", True) and "sales_million" in left_tbl:
        rows["ë§¤ì¶œì•¡(ë°±ë§Œì›)|ì‹¤ì "] = left_tbl["sales_million"].round(0).astype("Int64").tolist()
    if st.session_state.get("cb_pax", True) and "passengers_k" in left_tbl:
        rows["ìŠ¹ê°ìˆ˜(ì²œëª…)|ì‹¤ì "] = left_tbl["passengers_k"].round(0).astype("Int64").tolist()
    df = pd.DataFrame.from_dict(rows, orient="index", columns=fmt_date_ko(left_tbl["date"]))
    sums = []
    for idx in df.index:
        s = pd.to_numeric(df.loc[idx], errors="coerce").sum(min_count=1)
        sums.append("" if pd.isna(s) else int(round(s)))
    df.insert(0, "í•©ê³„", sums)
    return df

def _build_right_matrix() -> pd.DataFrame:
    if right_tbl.empty:
        return pd.DataFrame()
    def _delta_str(pct):
        if pd.isna(pct): return ""
        return f" ({'â–²' if pct>=0 else 'â–¼'}{abs(pct):.1f}%)"
    rows = {}
    if st.session_state.get("cb_sales", True) and "sales_million" in right_tbl:
        vals = right_tbl["sales_million"]
        pcts = merged_tbl["sales_pct"] if "sales_pct" in merged_tbl.columns else pd.Series([pd.NA]*len(vals))
        rows["ë§¤ì¶œì•¡(ë°±ë§Œì›)|ì˜ˆì¸¡(Î”)"] = [
            ("" if pd.isna(v) else f"{int(round(v)):,.0f}") + _delta_str(p)
            for v, p in zip(vals, pcts)
        ]
    if st.session_state.get("cb_pax", True) and "passengers_k" in right_tbl:
        vals = right_tbl["passengers_k"]
        pcts = merged_tbl["pax_pct"] if "pax_pct" in merged_tbl.columns else pd.Series([pd.NA]*len(vals))
        rows["ìŠ¹ê°ìˆ˜(ì²œëª…)|ì˜ˆì¸¡(Î”)"] = [
            ("" if pd.isna(v) else f"{int(round(v)):,.0f}") + _delta_str(p)
            for v, p in zip(vals, pcts)
        ]
    df = pd.DataFrame.from_dict(rows, orient="index", columns=fmt_date_ko(right_tbl["date"]))
    sum_col = []
    for idx in df.index:
        if idx.startswith("ë§¤ì¶œì•¡"):
            s = pd.to_numeric(right_tbl.get("sales_million"), errors="coerce").sum(min_count=1)
            sum_col.append("" if pd.isna(s) else f"{int(round(s)):,.0f}")
        elif idx.startswith("ìŠ¹ê°ìˆ˜"):
            s = pd.to_numeric(right_tbl.get("passengers_k"), errors="coerce").sum(min_count=1)
            sum_col.append("" if pd.isna(s) else f"{int(round(s)):,.0f}")
        else:
            sum_col.append("")
    df.insert(0, "í•©ê³„", sum_col)
    return df

left_matrix  = _build_left_matrix()
right_matrix = _build_right_matrix()

def _transpose_with_sum_first(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty: return pd.DataFrame()
    t = df.T
    if "í•©ê³„" in t.index:
        t = pd.concat([t.loc[["í•©ê³„"]], t.drop(index=["í•©ê³„"])], axis=0)
    return t

left_T  = _transpose_with_sum_first(left_matrix)
right_T = _transpose_with_sum_first(right_matrix)

# ==== ì „ì¹˜í‘œ: ì™¸ë¶€ìš”ì¸/íœ´ì¼ ì»¬ëŸ¼ ì¶”ê°€ ë° í¬ë§· ====
if not left_T.empty and not left_tbl.empty:
    ext_values = build_event_strings(pd.DatetimeIndex(left_tbl["date"]), external_factors_df)
    left_holiday_labels2, _ = build_holiday_labels(pd.DatetimeIndex(left_tbl["date"]), holidays_df, max_len=6)

    def _append_aligned_column(T: pd.DataFrame, dates: pd.Series, values: list, col_name: str):
        if T is None or T.empty: return T
        date_labels = list(fmt_date_ko(pd.Series(dates)))
        mapping = {lbl: val for lbl, val in zip(date_labels, values)}
        aligned = []
        for idx in T.index:
            aligned.append("" if str(idx) == "í•©ê³„" else mapping.get(idx, ""))
        T[col_name] = aligned
        return T

    left_T = _append_aligned_column(left_T, left_tbl["date"], ext_values, "ì™¸ë¶€ìš”ì¸")
    left_T = _append_aligned_column(left_T, left_tbl["date"], left_holiday_labels2, "íœ´ì¼")

    # ìˆ«ì í¬ë§·(3ìë¦¬ ì½¤ë§ˆ)
    def _fmt_commas(v):
        if v is None or (isinstance(v, float) and pd.isna(v)) or (isinstance(v, str) and v.strip() == ""):
            return ""
        try:
            n = pd.to_numeric(v, errors="coerce")
            if pd.isna(n):
                return str(v)
            return f"{int(round(n)):,}"
        except Exception:
            return str(v)
    num_cols = [c for c in left_T.columns if ("ë§¤ì¶œì•¡" in c) or ("ìŠ¹ê°ìˆ˜" in c)]
    for c in num_cols:
        left_T[c] = left_T[c].apply(_fmt_commas)

# ==== ì˜ˆì¸¡ê¸°ê°„(ì „ì¹˜): íœ´ì¼ ì»¬ëŸ¼ë§Œ ë§¨ ëì— ====
if not right_T.empty and not right_tbl.empty:
    def _append_aligned_column(T: pd.DataFrame, dates: pd.Series, values: list, col_name: str):
        if T is None or T.empty: return T
        date_labels = list(fmt_date_ko(pd.Series(dates)))
        mapping = {lbl: val for lbl, val in zip(date_labels, values)}
        aligned = []
        for idx in T.index:
            aligned.append("" if str(idx) == "í•©ê³„" else mapping.get(idx, ""))
        T[col_name] = aligned
        return T
    if "íœ´ë¬´" in right_T.columns:
        right_T = right_T.drop(columns=["íœ´ë¬´"])
    right_holiday_labels2, _ = build_holiday_labels(pd.DatetimeIndex(right_tbl["date"]), holidays_df, max_len=6)
    if "íœ´ì¼" in right_T.columns:
        _col = right_T.pop("íœ´ì¼")
        right_T["íœ´ì¼"] = _col
    else:
        right_T = _append_aligned_column(right_T, right_tbl["date"], right_holiday_labels2, "íœ´ì¼")

# ==== (ì¤‘ìš”) ìµœì´ˆ ì§„ì…/ê¸°ê°„ ë³€ê²½ ì‹œ ì´ë²¤íŠ¸ ë§µ ì„ ìƒì„± ====
@st.cache_data(show_spinner=False)
def load_concert_counts_df() -> pd.DataFrame:
    try:
        df = load_df_from_repo_csv("merged.csv").copy()
    except FileNotFoundError:
        st.warning("'merged.csv'ë¥¼ ì°¾ì§€ ëª»í•´ ì½˜ì„œíŠ¸ ì¹´ìš´íŠ¸ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(columns=["date","concerts_events_count"])
    cols = {c.lower(): c for c in df.columns}
    need = ["date","concerts_events_count"]
    for k in need:
        if k not in [c.lower() for c in df.columns]:
            st.warning(f"'merged.csv'ì— '{k}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame(columns=["date","concerts_events_count"])
    df.rename(columns={cols.get("date","date"):"date",
                       cols.get("concerts_events_count","concerts_events_count"):"concerts_events_count"}, inplace=True)
    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    df["concerts_events_count"] = pd.to_numeric(df["concerts_events_count"], errors="coerce").fillna(0).astype(int)
    df = df.dropna(subset=["date"]).sort_values("date")
    df = df[(df["date"] >= ACT_START) & (df["date"] <= ACT_END)]
    return df[["date","concerts_events_count"]]

@st.cache_data(show_spinner=False)
def load_concert_info_df() -> pd.DataFrame:
    try:
        df = load_df_from_repo_csv("concert_info_rows.csv").copy()
    except FileNotFoundError:
        st.warning("'concert_info_rows.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì½˜ì„œíŠ¸ ìƒì„¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return pd.DataFrame(columns=["title","start_date","end_date","label"])
    required = ["title","s_y","s_m","s_d","e_y","e_m","e_d"]
    missing = [c for c in required if c not in df.columns]
    if missing:
        st.warning(f"'concert_info_rows.csv'ì— ë‹¤ìŒ ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤: {', '.join(missing)}")
        return pd.DataFrame(columns=["title","start_date","end_date","label"])

    def _to_int(s):
        return pd.to_numeric(pd.Series(s, dtype=str).str.replace(r"[^\d]", "", regex=True), errors="coerce").astype("Int64")

    for c in ["s_y","s_m","s_d","e_y","e_m","e_d"]:
        df[c] = _to_int(df[c])

    s_str = (df["s_y"].astype(str).str.zfill(4) + "-" +
             df["s_m"].astype(str).str.zfill(2) + "-" +
             df["s_d"].astype(str).str.zfill(2))
    e_str = (df["e_y"].astype(str).str.zfill(4) + "-" +
             df["e_m"].astype(str).str.zfill(2) + "-" +
             df["e_d"].astype(str).str.zfill(2))

    df["start_date"] = pd.to_datetime(s_str, errors="coerce")
    df["end_date"]   = pd.to_datetime(e_str, errors="coerce")
    df = df.dropna(subset=["start_date","end_date"])
    df = df[df["start_date"] <= df["end_date"]].copy()
    df["label"] = "(Concert)" + df["title"].astype(str) + " (" + df["start_date"].dt.strftime("%Y-%m-%d") + "~" + df["end_date"].dt.strftime("%Y-%m-%d") + ")"
    return df[["title","start_date","end_date","label"]]

def build_concert_map_by_date(visible_dates: pd.DatetimeIndex,
                              counts_df: pd.DataFrame,
                              info_df: pd.DataFrame) -> dict:
    if visible_dates is None or len(visible_dates) == 0 or counts_df is None or counts_df.empty or info_df is None or info_df.empty:
        return {}
    counts = counts_df.set_index("date").reindex(visible_dates).fillna(0)
    target_days = [d.normalize() for d in visible_dates if counts.loc[d, "concerts_events_count"] > 0]
    if not target_days:
        return {}
    target_set = set(target_days)
    bucket = {d: [] for d in target_days}
    min_d, max_d = min(target_set), max(target_set)
    for _, row in load_concert_info_df().iterrows() if info_df is None else info_df.iterrows():
        s, e, label = row["start_date"].normalize(), row["end_date"].normalize(), str(row["label"])
        if pd.isna(s) or pd.isna(e) or label.strip() == "": continue
        if e < min_d or s > max_d: continue
        start = max(s, min_d); end = min(e, max_d)
        for d in pd.date_range(start, end, freq="D"):
            d0 = d.normalize()
            if d0 in target_set:
                bucket[d0].append(label)
    bucket = {d: [t for t in titles if t.strip() != ""] for d, titles in bucket.items()}
    return {d: titles for d, titles in bucket.items() if titles}

@st.cache_data(show_spinner=False)
def load_expo_counts_df() -> pd.DataFrame:
    try:
        df = load_df_from_repo_csv("merged.csv").copy()
    except FileNotFoundError:
        st.warning("'merged.csv'ë¥¼ ì°¾ì§€ ëª»í•´ ë°•ëŒíšŒ ì¹´ìš´íŠ¸ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(columns=["date","coex_events_count","kintex_events_count","bexco_events_count"])
    cols = {c.lower(): c for c in df.columns}
    need = ["date","coex_events_count","kintex_events_count","bexco_events_count"]
    for k in need:
        if k not in [c.lower() for c in df.columns]:
            st.warning(f"'merged.csv'ì— '{k}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame(columns=["date","coex_events_count","kintex_events_count","bexco_events_count"])
    df.rename(columns={
        cols.get("date","date"): "date",
        cols.get("coex_events_count","coex_events_count"): "coex_events_count",
        cols.get("kintex_events_count","kintex_events_count"): "kintex_events_count",
        cols.get("bexco_events_count","bexco_events_count"): "bexco_events_count",
    }, inplace=True)
    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    for c in ["coex_events_count","kintex_events_count","bexco_events_count"]:
        df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0).astype(int)
    df = df.dropna(subset=["date"]).sort_values("date")
    df = df[(df["date"] >= ACT_START) & (df["date"] <= ACT_END)]
    return df[["date","coex_events_count","kintex_events_count","bexco_events_count"]]

@st.cache_data(show_spinner=False)
def load_expo_info_df(file_name: str, venue_prefix: str) -> pd.DataFrame:
    try:
        df = load_df_from_repo_csv(file_name).copy()
    except FileNotFoundError:
        st.warning(f"'{file_name}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ({venue_prefix} ìƒì„¸ ê±´ë„ˆëœ€)")
        return pd.DataFrame(columns=["event_name","start_date","end_date","label"])
    if "event_name" not in df.columns:
        st.warning(f"'{file_name}'ì— 'event_name' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        df["event_name"] = ""
    start_col = "start_date" if "start_date" in df.columns else ("strart_date" if "strart_date" in df.columns else None)
    end_col   = "end_date" if "end_date" in df.columns else None
    if start_col is None or end_col is None:
        st.warning(f"'{file_name}'ì— ì‹œì‘/ì¢…ë£Œì¼ ì»¬ëŸ¼(start_date/strart_date, end_date)ì´ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(columns=["event_name","start_date","end_date","label"])
    df["start_date"] = pd.to_datetime(df[start_col], errors="coerce")
    df["end_date"]   = pd.to_datetime(df[end_col],   errors="coerce")
    df = df.dropna(subset=["start_date","end_date"])
    df = df[df["start_date"] <= df["end_date"]].copy()
    df["event_name"] = df["event_name"].astype(str)
    df["label"] = "(" + venue_prefix + ")" + df["event_name"] + " (" + \
                  df["start_date"].dt.strftime("%Y-%m-%d") + "~" + df["end_date"].dt.strftime("%Y-%m-%d") + ")"
    return df[["event_name","start_date","end_date","label"]]

def build_event_titles_by_date(visible_dates: pd.DatetimeIndex,
                               counts_df: pd.DataFrame,
                               info_df: pd.DataFrame,
                               count_col: str) -> dict:
    if visible_dates is None or len(visible_dates) == 0:
        return {}
    if counts_df is None or counts_df.empty or info_df is None or info_df.empty:
        return {}
    counts = counts_df.set_index("date").reindex(visible_dates).fillna(0)
    target_days = [d.normalize() for d in visible_dates if (count_col in counts.columns and counts.loc[d, count_col] > 0)]
    if not target_days:
        return {}
    target_set = set(target_days)
    bucket = {d: [] for d in target_days}
    min_d, max_d = min(target_set), max(target_set)
    for _, row in info_df.iterrows():
        s, e, label = pd.to_datetime(row["start_date"]).normalize(), pd.to_datetime(row["end_date"]).normalize(), str(row["label"])
        if pd.isna(s) or pd.isna(e) or label.strip() == "":
            continue
        if e < min_d or s > max_d:
            continue
        start = max(s, min_d); end = min(e, max_d)
        if start > end:
            continue
        for d in pd.date_range(start, end, freq="D"):
            d0 = d.normalize()
            if d0 in target_set:
                bucket[d0].append(label)
    bucket = {d: [t for t in titles if t.strip() != ""] for d, titles in bucket.items()}
    bucket = {d: titles for d, titles in bucket.items() if titles}
    return bucket

@st.cache_data(show_spinner=False)
def load_sports_counts_df() -> pd.DataFrame:
    try:
        df = load_df_from_repo_csv("merged.csv").copy()
    except FileNotFoundError:
        st.warning("'merged.csv'ë¥¼ ì°¾ì§€ ëª»í•´ ìŠ¤í¬ì¸  ì¹´ìš´íŠ¸ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(columns=["date","games_baseball","games_soccer"])
    cols = {c.lower(): c for c in df.columns}
    need = ["date","games_baseball","games_soccer"]
    for k in need:
        if k not in [c.lower() for c in df.columns]:
            st.warning(f"'merged.csv'ì— '{k}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame(columns=["date","games_baseball","games_soccer"])
    df.rename(columns={
        cols.get("date","date"): "date",
        cols.get("games_baseball","games_baseball"): "games_baseball",
        cols.get("games_soccer","games_soccer"): "games_soccer",
    }, inplace=True)
    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    for c in ["games_baseball","games_soccer"]:
        df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0).astype(int)
    df = df.dropna(subset=["date"]).sort_values("date")
    df = df[(df["date"] >= ACT_START) & (df["date"] <= ACT_END)]
    return df[["date","games_baseball","games_soccer"]]

@st.cache_data(show_spinner=False)
def load_baseball_schedule_df() -> pd.DataFrame:
    try:
        df = load_df_from_repo_csv("baseball_schedule_rows.csv").copy()
    except FileNotFoundError:
        st.warning("'baseball_schedule_rows.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì•¼êµ¬ ì¼ì • ìƒëµ)")
        return pd.DataFrame(columns=["date","label"])
    required = ["game_date","home_team","away_team","region"]
    missing = [c for c in required if c not in df.columns]
    if missing:
        st.warning(f"ì•¼êµ¬ ì¼ì •ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing)}")
        return pd.DataFrame(columns=["date","label"])
    df["game_date"] = pd.to_datetime(df["game_date"], errors="coerce").dt.normalize()
    df = df.dropna(subset=["game_date"]).copy()
    if "note" in df.columns:
        mask_keep = df["note"].isna() | (df["note"].astype(str).str.strip() == "")
        df = df[mask_keep].copy()
    for c in ["home_team","away_team","region"]:
        df[c] = df[c].astype(str).fillna("")
    df["label"] = "(Baseball)" + df["home_team"] + " VS " + df["away_team"] + " in " + df["region"]
    df.rename(columns={"game_date":"date"}, inplace=True)
    return df[["date","label"]]

@st.cache_data(show_spinner=False)
def load_kleague_schedule_df() -> pd.DataFrame:
    try:
        df = load_df_from_repo_csv("k_league_rows.csv").copy()
    except FileNotFoundError:
        st.warning("'k_league_rows.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (Kë¦¬ê·¸ ì¼ì • ìƒëµ)")
        return pd.DataFrame(columns=["date","label"])
    for c in ["date","class","stadium"]:
        if c not in df.columns:
            df[c] = ""
    df["date"] = pd.to_datetime(df["date"], errors="coerce").dt.normalize()
    df = df.dropna(subset=["date"]).copy()
    df["class"]   = df["class"].astype(str)
    df["stadium"] = df["stadium"].astype(str)
    df["label"] = "(K-league)" + df["class"] + " in " + df["stadium"]
    return df[["date","label"]]

def build_single_day_titles_by_date(visible_dates: pd.DatetimeIndex,
                                    counts_df: pd.DataFrame,
                                    info_df: pd.DataFrame,
                                    count_col: str,
                                    info_date_col: str = "date") -> dict:
    if visible_dates is None or len(visible_dates) == 0:
        return {}
    if counts_df is None or counts_df.empty or info_df is None or info_df.empty:
        return {}
    counts = counts_df.set_index("date").reindex(visible_dates).fillna(0)
    target_days = [d.normalize() for d in visible_dates if (count_col in counts.columns and counts.loc[d, count_col] > 0)]
    if not target_days:
        return {}
    info_df = info_df.copy()
    info_df[info_date_col] = pd.to_datetime(info_df[info_date_col]).dt.normalize()
    by_date = (info_df.groupby(info_date_col)["label"]
                     .apply(lambda s: [str(x) for x in s if isinstance(x, str) and x.strip() != ""])
                     .to_dict())
    bucket = {}
    for d in target_days:
        labels = by_date.get(d, [])
        if labels:
            bucket[d] = labels
    return bucket

def _build_integrated_map_for_range(s: pd.Timestamp, e: pd.Timestamp) -> dict:
    if s is None or e is None or s > e:
        return {}
    visible_left = pd.date_range(s, e, freq="D")
    concert_counts_df = load_concert_counts_df()
    concert_info_df   = load_concert_info_df()
    concert_map = build_concert_map_by_date(visible_left, concert_counts_df, concert_info_df)
    expo_counts_df = load_expo_counts_df()
    coex_info_df   = load_expo_info_df("coex_events_rows.csv",   "Coex")
    kintex_info_df = load_expo_info_df("kintex_events_rows.csv", "Kintex")
    bexco_info_df  = load_expo_info_df("bexco_events_rows.csv",  "Bexco")
    coex_map   = build_event_titles_by_date(visible_left, expo_counts_df, coex_info_df,   "coex_events_count")
    kintex_map = build_event_titles_by_date(visible_left, expo_counts_df, kintex_info_df, "kintex_events_count")
    bexco_map  = build_event_titles_by_date(visible_left, expo_counts_df, bexco_info_df,  "bexco_events_count")
    sports_counts_df = load_sports_counts_df()
    baseball_df = load_baseball_schedule_df()
    kleague_df  = load_kleague_schedule_df()
    baseball_map = build_single_day_titles_by_date(visible_left, sports_counts_df, baseball_df, "games_baseball", info_date_col="date")
    kleague_map  = build_single_day_titles_by_date(visible_left, sports_counts_df, kleague_df,  "games_soccer",   info_date_col="date")
    out = {}
    for d in visible_left:
        d0 = d.normalize()
        items = []
        items += concert_map.get(d0, [])
        items += coex_map.get(d0, [])
        items += kintex_map.get(d0, [])
        items += bexco_map.get(d0, [])
        items += baseball_map.get(d0, [])
        items += kleague_map.get(d0, [])
        if items:
            out[d0] = items
    return out

# â”€â”€ ì„¸ì…˜ì— ì—†ê±°ë‚˜ ê¸°ê°„ ë°”ë€Œë©´ ì„ ìƒì„±
_prev = st.session_state.get("_evt_map_range", None)
_cur = (l_s, l_e)
need_build = ("integrated_event_map" not in st.session_state) or (_prev != _cur)
if need_build:
    st.session_state["integrated_event_map"] = _build_integrated_map_for_range(l_s, l_e)
    st.session_state["_evt_map_range"] = _cur

# ---- (ë„ìš°ë¯¸) ì „ì¹˜ í…Œì´ë¸”ì˜ ì¸ë±ìŠ¤ì— ë§ì¶° ì•ˆì „í•˜ê²Œ ì»¬ëŸ¼ ì¶”ê°€ (ì¬ì‚¬ìš©ìš©)
def _append_aligned_column(T: pd.DataFrame, dates: pd.Series, values: list, col_name: str):
    if T is None or T.empty:
        return T
    date_labels = list(fmt_date_ko(pd.Series(dates)))
    mapping = {lbl: val for lbl, val in zip(date_labels, values)}
    aligned = []
    for idx in T.index:
        if str(idx) == "í•©ê³„":
            aligned.append("")
        else:
            aligned.append(mapping.get(idx, ""))
    T[col_name] = aligned
    return T

# ---- ìŠ¤íƒ€ì¼ (ì£¼ë§ ìƒ‰) â”€â”€ st.data_editorë¡œ ë³€ê²½í•˜ë©´ì„œ ì‚¬ìš© X, í•„ìš” ì‹œ ì»¬ëŸ¼ìœ¼ë¡œ ëŒ€ì²´ ê°€ëŠ¥
def _style_weekend_rows(df: pd.DataFrame) -> Styler:
    blue_text = "#1e90ff"; red_text = "#ef4444"
    sty = df.style.set_properties(**{"text-align":"center"}).set_table_styles([{"selector":"th","props":"text-align:center;"}])
    if "í•©ê³„" in df.index:
        sty = sty.set_properties(subset=(["í•©ê³„"], df.columns), **{"font-weight":"bold","background-color": SUM_BG})
    for idx in df.index:
        if isinstance(idx, str) and "(í† )" in idx:
            sty = sty.set_properties(subset=([idx], df.columns), **{"color": blue_text})
        if isinstance(idx, str) and "(ì¼)" in idx:
            sty = sty.set_properties(subset=([idx], df.columns), **{"color": red_text})
    return sty

# ---- ì¶œë ¥ (ì „ì¹˜í‘œ + ì²´í¬ë°•ìŠ¤ + ì„ íƒëœ ì¼ì ì´ë²¤íŠ¸) ----
c1, c2 = st.columns(2)
with c1:
    st.markdown("**âœ…ì‹¤ì **")
    if left_T.empty:
        st.info("ì‹¤ì  ê¸°ê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ì¸ë±ìŠ¤('ì¼ì')ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ êº¼ë‚´ê³  'ì™¸ë¶€ìš”ì¸' ì˜†ì— ì²´í¬ë°•ìŠ¤ ì¶”ê°€
        left_T.index.name = "ì¼ì"
        left_edit = left_T.reset_index()

        insert_pos = left_edit.columns.get_loc("ì™¸ë¶€ìš”ì¸") + 1 if "ì™¸ë¶€ìš”ì¸" in left_edit.columns else len(left_edit.columns)
        if "ì„ íƒ" not in left_edit.columns:
            left_edit.insert(insert_pos, "ì„ íƒ", False)

        edited_left = st.data_editor(
            left_edit,
            hide_index=True,
            use_container_width=True,
            height=min(520, 140 + 28 * max(3, len(left_edit))),
            column_config={
                "ì„ íƒ": st.column_config.CheckboxColumn(
                    "ì„ íƒ", help="í•´ë‹¹ ì¼ìì˜ ì´ë²¤íŠ¸ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.", default=False,
                ),
            },
            disabled=["ì¼ì"],  # ë‚ ì§œ ìˆ˜ì • ë°©ì§€
        )

        # âœ… ì²´í¬ëœ ë‚ ì§œ ì €ì¥ (í•©ê³„ ì œì™¸) â€” ìƒì„¸ë³´ê¸° í‘œëŠ” ì•„ë˜ ì „ìš© ì„¹ì…˜ì—ì„œ ì „ì²´í­ìœ¼ë¡œ ë Œë”ë§
        selected_mask = (edited_left.get("ì„ íƒ") == True) & (edited_left.get("ì¼ì") != "í•©ê³„")
        st.session_state["selected_event_dates_from_matrix"] = edited_left.loc[selected_mask, "ì¼ì"].tolist()

with c2:
    st.markdown("**âœ…ì˜ˆì¸¡**")
    if right_T.empty:
        st.info("ì˜ˆì¸¡ ê¸°ê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        right_T.index.name = "ì¼ì"
        st.dataframe(_style_weekend_rows(right_T), use_container_width=True,
                     height=min(520, 140 + 28 * max(3, len(right_T))))

# ===================== ğŸ” ì™¸ë¶€ìš”ì¸ ìƒì„¸ë³´ê¸° (ì „ì²´ í­) =====================
st.markdown("#### ğŸ” ì™¸ë¶€ìš”ì¸ ìƒì„¸ë³´ê¸°")

def _label_to_date(lbl: str):
    try:
        s = str(lbl).strip()
        iso = s[:10]
        dt = pd.to_datetime(iso, errors="coerce")
        return None if pd.isna(dt) else dt.normalize()
    except Exception:
        return None

_selected_labels = st.session_state.get("selected_event_dates_from_matrix", []) or []
_selected_dates = [d for d in (_label_to_date(x) for x in _selected_labels) if d is not None]
_selected_dates = sorted(set(_selected_dates))

integrated_map = st.session_state.get("integrated_event_map", {})

if not _selected_dates:
    st.info("ì²´í¬í•œ ë‚ ì§œê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    def build_event_detail_df(selected_dates: list[pd.Timestamp], event_map: dict) -> dict:
        """ì„ íƒëœ ë‚ ì§œë³„ ê°œë³„ DataFrame ìƒì„±"""
        result = {}
        for d0 in selected_dates:
            pretty = fmt_date_ko(pd.Series([d0])).iloc[0]
            events = event_map.get(d0, [])
            rows = []

            if not events:
                rows.append({"ì¹´í…Œê³ ë¦¬": "", "ì´ë²¤íŠ¸": "(í‘œì‹œí•  ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤)", "ê¸°ê°„": "", "ë¹„ê³ ": ""})
            else:
                for t in events:
                    raw = str(t).strip()
                    # (ì¹´í…Œê³ ë¦¬) ì œëª© (2024-01-01~2024-01-03) í˜•íƒœ ë¶„ë¦¬
                    m = re.match(r"^\(([^)]+)\)\s*(.*)$", raw)
                    cat = m.group(1) if m else ""
                    title = m.group(2) if m else raw

                    # ì¹´í…Œê³ ë¦¬ ë³€í™˜
                    if cat.lower() == "concert":
                        cat_kr = "ì½˜ì„œíŠ¸"
                    elif cat.lower() in ["coex", "bexco", "kintex"]:
                        cat_kr = "ë°•ëŒíšŒ"
                    elif cat.lower() in ["baseball", "k-league"]:
                        cat_kr = "ìŠ¤í¬ì¸ "
                    else:
                        cat_kr = cat

                    # ê¸°ê°„ ì¶”ì¶œ
                    period_match = re.search(r"\((\d{4}-\d{2}-\d{2}~\d{4}-\d{2}-\d{2})\)", title)
                    period = period_match.group(1) if period_match else ""
                    title_clean = re.sub(r"\(\d{4}-\d{2}-\d{2}~\d{4}-\d{2}-\d{2}\)", "", title).strip()

                    # ì½˜ì„œíŠ¸ ì™¸ ì¹´í…Œê³ ë¦¬ëŠ” "(ì¹´í…Œê³ ë¦¬)" ì ‘ë‘ì–´ ì¶”ê°€
                    if cat_kr != "ì½˜ì„œíŠ¸" and cat:
                        title_clean = f"({cat}) " + title_clean

                    rows.append({
                        "ì¹´í…Œê³ ë¦¬": cat_kr,
                        "ì´ë²¤íŠ¸": title_clean,
                        "ê¸°ê°„": period,
                        "ë¹„ê³ ": ""
                    })
            result[d0] = pd.DataFrame(rows, columns=["ì¹´í…Œê³ ë¦¬", "ì´ë²¤íŠ¸", "ê¸°ê°„", "ë¹„ê³ "])
        return result

    # ë‚ ì§œë³„ ê°œë³„ í‘œ ìƒì„±
    detail_map = build_event_detail_df(_selected_dates, integrated_map)

    # ê° ë‚ ì§œë³„ í‘œë¥¼ ê°œë³„ë¡œ ë Œë”ë§
    for d0 in _selected_dates:
        df_day = detail_map.get(d0, pd.DataFrame())
        pretty = fmt_date_ko(pd.Series([d0])).iloc[0]
        st.markdown(f"**ğŸ“… {pretty}**")
        if df_day.empty:
            st.info("ì´ ë‚ ì§œì—ëŠ” í‘œì‹œí•  ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.dataframe(
                df_day,
                use_container_width=True,
                height=min(380, 120 + 28 * (len(df_day) + 1))
            )
        st.markdown("---")




# ===================== 9ì›” ì˜ˆì¸¡ ì •í™•ë„ (ì‹¤ì  vs ì˜ˆì¸¡) =====================
st.markdown("#### ğŸ¯ ì˜ˆì¸¡ ì •í™•ë„ (ì‹¤ì  vs ì˜ˆì¸¡)")

SEP_START = pd.to_datetime("2025-09-01")
SEP_END   = pd.to_datetime("2025-09-30")

@st.cache_data(show_spinner=False)
def load_actual_sep_df() -> pd.DataFrame:
    SEP_START = pd.to_datetime("2025-09-01")
    SEP_END   = pd.to_datetime("2025-09-30")
    try:
        raw = load_df_from_repo_csv("actual_sep_rows.csv").copy()
    except FileNotFoundError:
        st.warning("'actual_sep_rows.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (9ì›” ì •í™•ë„ í‘œ ìƒëµ)")
        return pd.DataFrame(columns=["date","passengers","sales_amount"])
    if raw.empty:
        st.warning("actual_sep_rows.csvê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return pd.DataFrame(columns=["date","passengers","sales_amount"])
    df = raw.copy()
    df.columns = [str(c).strip().lower() for c in df.columns]
    date_col_candidates = ["travel_date","date","ì¼ì","ë‚ ì§œ","ts","dt"]
    ymd_candidates = [("year","month","day"),("yyyy","mm","dd"),("y","m","d"),("s_y","s_m","s_d")]
    date_series = None
    for c in date_col_candidates:
        if c in df.columns:
            date_series = pd.to_datetime(df[c], errors="coerce")
            break
    if date_series is None:
        for y,m,d in ymd_candidates:
            if y in df.columns and m in df.columns and d in df.columns:
                yv = pd.to_numeric(df[y], errors="coerce")
                mv = pd.to_numeric(df[m], errors="coerce")
                dv = pd.to_numeric(df[d], errors="coerce")
                date_series = pd.to_datetime(
                    yv.astype("Int64").astype(str).str.zfill(4) + "-" +
                    mv.astype("Int64").astype(str).str.zfill(2) + "-" +
                    dv.astype("Int64").astype(str).str.zfill(2),
                    errors="coerce"
                )
                break
    if date_series is None:
        st.warning("actual_sep_rows.csvì—ì„œ ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (travel_date/date/ì¼ì/ë‚ ì§œ ë˜ëŠ” ì—°Â·ì›”Â·ì¼ ì¡°í•© í•„ìš”)")
        return pd.DataFrame(columns=["date","passengers","sales_amount"])
    df["date"] = pd.to_datetime(date_series, errors="coerce").dt.normalize()

    def _pick_col(cands):
        for c in cands:
            if c in df.columns: return c
        for c in df.columns:
            for key in cands:
                if key in c: return c
        return None
    pax_col = _pick_col(["passengers","pax","ridership","ìŠ¹ê°","ìŠ¹ê°ìˆ˜"])
    sales_col = _pick_col(["sales_amount","sales","revenue","amount","ë§¤ì¶œ","ë§¤ì¶œì•¡"])
    def to_numeric_clean(s):
        if s is None: return pd.Series(dtype="float64")
        return (pd.Series(s, dtype="object").astype(str)
                .str.replace(r"[,\sâ‚©ì›$â‚©]", "", regex=True)
                .replace({"": np.nan, "nan": np.nan})
                .pipe(pd.to_numeric, errors="coerce"))
    df["passengers"] = to_numeric_clean(df[pax_col]) if pax_col else np.nan
    df["sales_amount"] = to_numeric_clean(df[sales_col]) if sales_col else np.nan
    df = df.dropna(subset=["date"])
    if df[["passengers","sales_amount"]].isna().all(axis=None):
        st.warning("actual_sep_rows.csvì˜ ìŠ¹ê°/ë§¤ì¶œ ê°’ì´ ëª¨ë‘ ê²°ì¸¡ì…ë‹ˆë‹¤.")
        return pd.DataFrame(columns=["date","passengers","sales_amount"])
    daily = (df.groupby("date", as_index=False)[["passengers","sales_amount"]]
               .sum(min_count=1).sort_values("date"))
    daily = daily[(daily["date"] >= SEP_START) & (daily["date"] <= SEP_END)]
    if daily.empty:
        st.info("actual_sep_rows.csvì—ì„œ 2025-09 ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(columns=["date","passengers","sales_amount"])
    return daily[["date","passengers","sales_amount"]]

def _safe_pct_err(forecast, actual):
    if pd.isna(actual) or actual == 0:
        return np.nan
    return (forecast - actual) / actual * 100.0

actual_sep = load_actual_sep_df()
fcst_pass_sep = forecast_df_all[(forecast_df_all["date"] >= SEP_START) & (forecast_df_all["date"] <= SEP_END)][["date","passengers"]].rename(columns={"passengers":"f_passengers"})
fcst_sales_sep = forecast_sales_all[(forecast_sales_all["date"] >= SEP_START) & (forecast_sales_all["date"] <= SEP_END)][["date","pred_sales_amount"]].rename(columns={"pred_sales_amount":"f_sales_amount"})
fcst_sep = pd.merge(fcst_pass_sep, fcst_sales_sep, on="date", how="outer").sort_values("date")
sel_start = max(r_s, SEP_START); sel_end = min(r_e, SEP_END)
cmp = pd.merge(fcst_sep, actual_sep, on="date", how="outer")
cmp = cmp[(cmp["date"] >= sel_start) & (cmp["date"] <= sel_end)].sort_values("date").reset_index(drop=True)
cmp["a_passengers"]   = pd.to_numeric(cmp.get("passengers"), errors="coerce")
cmp["a_sales_amount"] = pd.to_numeric(cmp.get("sales_amount"), errors="coerce")
cmp["f_passengers"]   = pd.to_numeric(cmp.get("f_passengers"), errors="coerce")
cmp["f_sales_amount"] = pd.to_numeric(cmp.get("f_sales_amount"), errors="coerce")
cmp["pax_err_pct"]   = [ _safe_pct_err(fp, ap) for fp, ap in zip(cmp["f_passengers"], cmp["a_passengers"]) ]
cmp["sales_err_pct"] = [ _safe_pct_err(fs, as_) for fs, as_ in zip(cmp["f_sales_amount"], cmp["a_sales_amount"]) ]

disp = pd.DataFrame({
    "ì¼ì": fmt_date_ko(cmp["date"].dt.tz_localize(None)) if "date" in cmp.columns else pd.Series(dtype=str),
    "ì‹¤ì |ë§¤ì¶œì•¡(ë°±ë§Œì›)":  (cmp["a_sales_amount"] / 1_000_000).round(0).astype("Int64"),
    "ì˜ˆì¸¡|ë§¤ì¶œì•¡(ë°±ë§Œì›)":  (cmp["f_sales_amount"] / 1_000_000).round(0).astype("Int64"),
    "ì˜¤ì°¨ìœ¨|ë§¤ì¶œì•¡(%)":   cmp["sales_err_pct"].map(lambda x: f"{x:.1f}" if not pd.isna(x) else ""),
    "ì‹¤ì |ìŠ¹ê°ìˆ˜(ì²œëª…)":    (cmp["a_passengers"]  / 1_000).round(0).astype("Int64"),
    "ì˜ˆì¸¡|ìŠ¹ê°ìˆ˜(ì²œëª…)":    (cmp["f_passengers"]  / 1_000).round(0).astype("Int64"),
    "ì˜¤ì°¨ìœ¨|ìŠ¹ê°ìˆ˜(%)":   cmp["pax_err_pct"].map(lambda x: f"{x:.1f}" if not pd.isna(x) else ""),
})

def _mape_pct(f, a):
    s = [abs((fv - av)/av)*100.0 for fv, av in zip(f, a) if (not pd.isna(av) and av!=0 and not pd.isna(fv))]
    return np.nan if len(s)==0 else float(np.mean(s))

sum_a_pax   = cmp["a_passengers"].sum(skipna=True)
sum_f_pax   = cmp["f_passengers"].sum(skipna=True)
sum_a_sales = cmp["a_sales_amount"].sum(skipna=True)
sum_f_sales = cmp["f_sales_amount"].sum(skipna=True)
mape_pax   = _mape_pct(cmp["f_passengers"], cmp["a_passengers"])
mape_sales = _mape_pct(cmp["f_sales_amount"], cmp["a_sales_amount"])

sum_row2 = pd.DataFrame([{
    "ì¼ì": "í•©ê³„",
    "ì‹¤ì |ë§¤ì¶œì•¡(ë°±ë§Œì›)": int(round(sum_a_sales/1_000_000)) if not pd.isna(sum_a_sales) else pd.NA,
    "ì˜ˆì¸¡|ë§¤ì¶œì•¡(ë°±ë§Œì›)": int(round(sum_f_sales/1_000_000)) if not pd.isna(sum_f_sales) else pd.NA,
    "ì˜¤ì°¨ìœ¨|ë§¤ì¶œì•¡(%)":    round(mape_sales, 1) if not pd.isna(mape_sales) else pd.NA,
    "ì‹¤ì |ìŠ¹ê°ìˆ˜(ì²œëª…)":   int(round(sum_a_pax/1_000)) if not pd.isna(sum_a_pax) else pd.NA,
    "ì˜ˆì¸¡|ìŠ¹ê°ìˆ˜(ì²œëª…)":   int(round(sum_f_pax/1_000)) if not pd.isna(sum_f_pax) else pd.NA,
    "ì˜¤ì°¨ìœ¨|ìŠ¹ê°ìˆ˜(%)":    round(mape_pax, 1) if not pd.isna(mape_pax) else pd.NA,
}])

disp_out = pd.concat([sum_row2, disp], ignore_index=True)

def _weekday_textcolor_only_df(_df: pd.DataFrame) -> pd.DataFrame:
    blue_text = "#1e90ff"; red_text  = "#ef4444"
    styles = pd.DataFrame("", index=_df.index, columns=_df.columns)
    for i in _df.index[1:]:
        d = str(_df.at[i, "ì¼ì"]) if "ì¼ì" in _df.columns else ""
        if "(í† )" in d:
            styles.loc[i, :] = [f"color:{blue_text};"] * styles.shape[1]
        if "(ì¼)" in d:
            styles.loc[i, :] = [f"color:{red_text};"] * styles.shape[1]
    if 0 in styles.index:
        styles.loc[0, :] = [f"font-weight:bold; background-color:{SUM_BG};"] * styles.shape[1]
    return styles

# ==== ğŸ¯ ì˜ˆì¸¡ ì •í™•ë„ í‘œ ìˆ˜ì • ====

# ==== ğŸ¯ ì˜ˆì¸¡ ì •í™•ë„ í‘œ ìˆ˜ì • ====

# ìˆ«ì í¬ë§·(ì²œë‹¨ìœ„ ì½¤ë§ˆ)
def fmt_thousand(v):
    try:
        if pd.isna(v): return ""
        return f"{int(round(v)):,}"
    except Exception:
        return str(v)

disp_out_fmt = disp_out.copy()

# ì»¬ëŸ¼ëª… ë³€ê²½: 'ë§¤ì¶œì•¡', 'ìŠ¹ê°ìˆ˜' ë¬¸êµ¬ ì œê±°
disp_out_fmt = disp_out_fmt.rename(columns={
    "ì‹¤ì |ë§¤ì¶œì•¡(ë°±ë§Œì›)": "ì‹¤ì (ë°±ë§Œì›)",
    "ì˜ˆì¸¡|ë§¤ì¶œì•¡(ë°±ë§Œì›)": "ì˜ˆì¸¡(ë°±ë§Œì›)",
    "ì˜¤ì°¨ìœ¨|ë§¤ì¶œì•¡(%)": "ì˜¤ì°¨ìœ¨(%)",
    "ì‹¤ì |ìŠ¹ê°ìˆ˜(ì²œëª…)": "ì‹¤ì (ì²œëª…)",
    "ì˜ˆì¸¡|ìŠ¹ê°ìˆ˜(ì²œëª…)": "ì˜ˆì¸¡(ì²œëª…)",
    "ì˜¤ì°¨ìœ¨|ìŠ¹ê°ìˆ˜(%)": "ì˜¤ì°¨ìœ¨(%)_ìŠ¹ê°"
})

# ìˆ«ìì—´ ì²œë‹¨ìœ„ ì½¤ë§ˆ ì ìš©
num_cols = ["ì‹¤ì (ë°±ë§Œì›)", "ì˜ˆì¸¡(ë°±ë§Œì›)", "ì‹¤ì (ì²œëª…)", "ì˜ˆì¸¡(ì²œëª…)"]
for c in num_cols:
    if c in disp_out_fmt.columns:
        disp_out_fmt[c] = disp_out_fmt[c].apply(fmt_thousand)

# í•©ê³„í–‰ ì˜¤ì°¨ìœ¨ ì†Œìˆ˜ì  í•œìë¦¬ ìœ ì§€
for c in ["ì˜¤ì°¨ìœ¨(%)", "ì˜¤ì°¨ìœ¨(%)_ìŠ¹ê°"]:
    if c in disp_out_fmt.columns:
        val = str(disp_out_fmt.loc[0, c])
        if val.replace('.', '', 1).isdigit():
            disp_out_fmt.loc[0, c] = f"{float(val):.1f}"

# ì™¼ìª½(ë§¤ì¶œ), ì˜¤ë¥¸ìª½(ìŠ¹ê°) í‘œ ë¶„ë¦¬
disp_sales = disp_out_fmt[["ì¼ì", "ì‹¤ì (ë°±ë§Œì›)", "ì˜ˆì¸¡(ë°±ë§Œì›)", "ì˜¤ì°¨ìœ¨(%)"]].copy()
disp_pax   = disp_out_fmt[["ì¼ì", "ì‹¤ì (ì²œëª…)", "ì˜ˆì¸¡(ì²œëª…)", "ì˜¤ì°¨ìœ¨(%)_ìŠ¹ê°"]].copy()
disp_pax   = disp_pax.rename(columns={"ì˜¤ì°¨ìœ¨(%)_ìŠ¹ê°": "ì˜¤ì°¨ìœ¨(%)"})

# ìŠ¤íƒ€ì¼ ì ìš© (ì£¼ë§ ìƒ‰ìƒ, í•©ê³„ ê°•ì¡°)
def _weekday_textcolor_only_df(_df: pd.DataFrame) -> pd.DataFrame:
    blue_text = "#1e90ff"; red_text  = "#ef4444"
    styles = pd.DataFrame("", index=_df.index, columns=_df.columns)
    for i in _df.index[1:]:
        d = str(_df.at[i, "ì¼ì"]) if "ì¼ì" in _df.columns else ""
        if "(í† )" in d:
            styles.loc[i, :] = [f"color:{blue_text};"] * styles.shape[1]
        if "(ì¼)" in d:
            styles.loc[i, :] = [f"color:{red_text};"] * styles.shape[1]
    if 0 in styles.index:
        styles.loc[0, :] = [f"font-weight:bold; background-color:{SUM_BG};"] * styles.shape[1]
    return styles

# ë‘ í‘œ ë‚˜ë€íˆ ì¶œë ¥
col1, col2 = st.columns(2)
with col1:
    st.markdown("**ğŸ’° ë§¤ì¶œì•¡**")
    st.dataframe(
        disp_sales.style
            .set_properties(**{"text-align":"center"})
            .set_table_styles([{"selector":"th","props":"text-align:center;"}])
            .apply(_weekday_textcolor_only_df, axis=None),
        use_container_width=True,
        height=min(520, 120 + 28 * (len(disp_sales)+1))
    )
with col2:
    st.markdown("**ğŸš† ìŠ¹ê°ìˆ˜**")
    st.dataframe(
        disp_pax.style
            .set_properties(**{"text-align":"center"})
            .set_table_styles([{"selector":"th","props":"text-align:center;"}])
            .apply(_weekday_textcolor_only_df, axis=None),
        use_container_width=True,
        height=min(520, 120 + 28 * (len(disp_pax)+1))
    )

