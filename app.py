# app.py â”€â”€ Streamlit (https://<YOUR-APP>.streamlit.app)
import io
from pathlib import Path
from datetime import date
import pandas as pd
import numpy as np
import streamlit as st
import plotly.graph_objects as go

# ================= ê¸°ë³¸ ì„¤ì • =================
st.set_page_config(page_title="Passengers & Sales (Dual Axis)", layout="wide")
st.title("ğŸ“ˆ ì™¸ë¶€ìš”ì¸ ê¸°ë°˜ ì² ë„ìˆ˜ìš”ì˜ˆì¸¡ ì‹œìŠ¤í…œ")

# ================= ì‚¬ì´ë“œë°” ì˜µì…˜ =================
st.sidebar.header("ğŸ§° ì˜µì…˜")
interpolate_missing = st.sidebar.checkbox("ê²°ì¸¡ì¹˜ ë³´ê°„(ì„  ëŠê¹€ ë°©ì§€)", value=False)
use_rolling = st.sidebar.checkbox("ì´ë™í‰ê· (ìŠ¤ë¬´ë”©)", value=False)
window = st.sidebar.slider("ì´ë™í‰ê·  ìœˆë„ìš°(ì¼)", 2, 14, 3, 1, disabled=not use_rolling)

# ================= íŒŒì¼ ë¡œë” =================
@st.cache_data(show_spinner=False)
def load_df_from_repo_csv(filename: str):
    """CSV íŒŒì¼ì„ utf-8-sig â†’ cp949 ìˆœìœ¼ë¡œ ì½ê¸°"""
    path = Path(filename)
    if not path.exists():
        raise FileNotFoundError(f"'{filename}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    for enc in ("utf-8-sig", "cp949"):
        try:
            return pd.read_csv(path, encoding=enc)
        except Exception:
            continue
    return pd.read_csv(path)

# ===== ê¸°ê°„ ì •ì˜ =====
ACT_START = pd.to_datetime("2020-08-01")
ACT_END   = pd.to_datetime("2025-08-31")
FCT_START = pd.to_datetime("2025-09-01")
FCT_END   = pd.to_datetime("2025-11-29")

# ================= ì‹¤ì  ë°ì´í„° (merged.csv) =================
@st.cache_data(show_spinner=False)
def load_actual_df() -> pd.DataFrame:
    df = load_df_from_repo_csv("merged.csv").copy()
    cols = {c.lower(): c for c in df.columns}
    d = cols.get("date", "date")
    p = cols.get("passengers", "passengers")
    s = cols.get("sales_amount", "sales_amount")

    df.rename(columns={d: "date", p: "passengers", s: "sales_amount"}, inplace=True)
    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    df = df.dropna(subset=["date"]).sort_values("date")
    df = df[(df["date"] >= ACT_START) & (df["date"] <= ACT_END)]
    df["passengers"] = pd.to_numeric(df["passengers"], errors="coerce")
    df["sales_amount"] = pd.to_numeric(df["sales_amount"], errors="coerce")
    return df

# ================= ì˜ˆì¸¡ ë°ì´í„° (forecast_pass.csv) =================
@st.cache_data(show_spinner=False)
def load_forecast_df() -> pd.DataFrame:
    f = load_df_from_repo_csv("forecast_pass.csv").copy()
    cols = {c.lower(): c for c in f.columns}
    d = cols.get("date", "date")
    p = cols.get("forecast_90d", "forecast_90d")

    f.rename(columns={d: "date", p: "passengers"}, inplace=True)
    f["date"] = pd.to_datetime(f["date"], errors="coerce")
    f = f.dropna(subset=["date"]).sort_values("date")
    f = f[(f["date"] >= FCT_START) & (f["date"] <= FCT_END)]
    f["passengers"] = pd.to_numeric(f["passengers"], errors="coerce")
    f["sales_amount"] = np.nan  # ë§¤ì¶œì•¡ì€ ì—†ìŒ(ê·¸ë˜í”„ìš©)
    return f

# ================= ì˜ˆì¸¡ ë§¤ì¶œ ë¡œë” (forecast_sales.csv / .cvs í´ë°±) =================
@st.cache_data(show_spinner=False)
def load_forecast_sales_df() -> pd.DataFrame:
    """
    forecast_sales.csv(ìš°ì„ ) â†’ forecast_sales.cvs(í´ë°±)ì—ì„œ
    date, forecast_90dë¥¼ ì½ì–´ pred_sales_amountë¡œ ë°˜í™˜
    """
    try:
        f = load_df_from_repo_csv("forecast_sales.csv").copy()
    except FileNotFoundError:
        f = load_df_from_repo_csv("forecast_sales.cvs").copy()

    cols = {c.lower(): c for c in f.columns}
    d = cols.get("date", "date")
    v = cols.get("forecast_90d", "forecast_90d")

    f.rename(columns={d: "date", v: "pred_sales_amount"}, inplace=True)
    f["date"] = pd.to_datetime(f["date"], errors="coerce")
    f = f.dropna(subset=["date"]).sort_values("date")
    f = f[(f["date"] >= FCT_START) & (f["date"] <= FCT_END)]
    f["pred_sales_amount"] = pd.to_numeric(f["pred_sales_amount"], errors="coerce")
    return f[["date", "pred_sales_amount"]]

# ================= ì‹¤ì  ë¡œë” (train_reservations_rows.csv) =================
@st.cache_data(show_spinner=False)
def load_actual_rows_df() -> pd.DataFrame:
    """
    train_reservations_rows.csvì—ì„œ ì¼ìë³„ ì‹¤ì  ì§‘ê³„
    - ì…ë ¥ ì»¬ëŸ¼: travel_date, passengers, sales_amount
    - ì‰¼í‘œ ì œê±° í›„ float ë³€í™˜
    - ì¼ìë³„ í•©ê³„ ë°˜í™˜ (date, passengers, sales_amount)
    """
    df = load_df_from_repo_csv("train_reservations_rows.csv").copy()
    required = ["travel_date", "passengers", "sales_amount"]
    miss = [c for c in required if c not in df.columns]
    if miss:
        raise KeyError(f"'train_reservations_rows.csv'ì— ë‹¤ìŒ ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤: {', '.join(miss)}")

    df["travel_date"] = pd.to_datetime(df["travel_date"], errors="coerce")
    df = df.dropna(subset=["travel_date"])
    for c in ["passengers", "sales_amount"]:
        df[c] = (
            df[c].astype(str)
                 .str.replace(",", "", regex=False)
                 .replace("nan", np.nan)
        )
        df[c] = pd.to_numeric(df[c], errors="coerce")

    daily = (
        df.assign(date=df["travel_date"].dt.floor("D"))
          .groupby("date", as_index=False)[["passengers", "sales_amount"]]
          .sum()
          .sort_values("date")
    )
    return daily

# ================= ê¸°ê°„ ì„ íƒ (ì˜ˆì¸¡ê¸°ê°„ë§Œ) =================
data_min = FCT_START.date()
data_max = FCT_END.date()

start_date, end_date = st.session_state.get("selected_range", (data_min, data_max))
tl, tr = st.columns([0.78, 0.22])
with tl:
    st.subheader("ì˜ˆì¸¡ê·¸ë˜í”„")
with tr:
    with st.popover("ğŸ“… ê¸°ê°„ ì„¤ì •", use_container_width=True):
        sel = st.date_input("ì‹œì‘ì¼ / ì¢…ë£Œì¼ (ì˜ˆì¸¡ê¸°ê°„ë§Œ)",
                            value=(start_date, end_date),
                            min_value=data_min, max_value=data_max,
                            key="range_picker_v5")
        if isinstance(sel, tuple):
            sel_start, sel_end = sel
        else:
            sel_start, sel_end = sel, sel
        st.caption("ì„ íƒê¸°ê°„ ê¸¸ì´(Nì¼)ê³¼ ë™ì¼í•œ ì´ì „ Nì¼ ë°ì´í„°ë¥¼ í•¨ê»˜ í‘œì‹œí•©ë‹ˆë‹¤.")
start_date, end_date = pd.to_datetime(sel_start), pd.to_datetime(sel_end)
start_date = max(start_date, FCT_START)
end_date   = min(end_date,   FCT_END)
if start_date > end_date:
    st.stop()
st.session_state["selected_range"] = (start_date.date(), end_date.date())

# ================= ì´ì „ê¸°ê°„ ê³„ì‚° =================
N_days = (end_date - start_date).days + 1
prev_end   = start_date - pd.Timedelta(days=1)
prev_start = prev_end - pd.Timedelta(days=N_days - 1)

# ================= ë°ì´í„° ë¡œë“œ ë° ë³‘í•© =================
actual_df_all   = load_actual_df()
forecast_df_all = load_forecast_df()
# ì˜ˆì¸¡ ë§¤ì¶œ(ì—†ì–´ë„ ì•±ì´ ì£½ì§€ ì•Šë„ë¡ ë³´í˜¸)
try:
    forecast_sales_all = load_forecast_sales_df()
except FileNotFoundError as e:
    st.warning(f"ì˜ˆì¸¡ ë§¤ì¶œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ë§¤ì¶œ ì˜ˆì¸¡ì„ ì„ ê·¸ë¦¬ì§€ ëª»í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: {e}")
    forecast_sales_all = pd.DataFrame(columns=["date", "pred_sales_amount"])

def get_union_range(s, e):
    parts = []
    if not (e < ACT_START or s > ACT_END):
        a = actual_df_all[(actual_df_all["date"] >= s) & (actual_df_all["date"] <= e)]
        a = a.assign(source="actual")
        parts.append(a)
    if not (e < FCT_START or s > FCT_END):
        f = forecast_df_all[(forecast_df_all["date"] >= s) & (forecast_df_all["date"] <= e)]
        f = f.assign(source="forecast")
        parts.append(f)
    if parts:
        return pd.concat(parts, ignore_index=True).sort_values("date")
    return pd.DataFrame(columns=["date", "passengers", "sales_amount", "source"])

prev_df = get_union_range(prev_start, prev_end)
curr_df = get_union_range(start_date, end_date)
df_sel = pd.concat([
    prev_df.assign(period="ì´ì „ê¸°ê°„"),
    curr_df.assign(period="ì„ íƒê¸°ê°„")
], ignore_index=True).sort_values("date")

# --- ì˜ˆì¸¡ ë§¤ì¶œ ì£¼ì…: ì˜ˆì¸¡ êµ¬ê°„(source=='forecast')ì— pred_salesë¥¼ ì±„ì›Œ ì„ ì´ ëŠê¸°ì§€ ì•Šê²Œ í•¨
df_sel = df_sel.merge(forecast_sales_all, on="date", how="left")
df_sel["sales_amount"] = np.where(
    df_sel["source"].eq("forecast") & df_sel["sales_amount"].isna(),
    df_sel["pred_sales_amount"],
    df_sel["sales_amount"]
)

# ì „ì²˜ë¦¬(ë³´ê°„/ìŠ¤ë¬´ë”©ì€ ì£¼ì…ëœ sales_amountì— ëŒ€í•´ ì ìš©)
if interpolate_missing and not df_sel.empty:
    df_sel = (df_sel.set_index("date")
              .groupby("period", group_keys=False)
              .apply(lambda g: g[["passengers","sales_amount"]]
                     .resample("D").asfreq()
              ).reset_index())
    df_sel[["passengers","sales_amount"]] = df_sel[["passengers","sales_amount"]].interpolate(method="time")

if use_rolling and not df_sel.empty:
    df_sel[["passengers","sales_amount"]] = (
        df_sel.groupby("period")[["passengers","sales_amount"]]
              .transform(lambda s: s.rolling(window=window, min_periods=1).mean())
    )

df_sel["sales_million"] = pd.to_numeric(df_sel["sales_amount"], errors="coerce") / 1_000_000

# ================= ê·¸ë˜í”„ =================
def intersect(a1, a2, b1, b2):
    s = max(pd.to_datetime(a1), pd.to_datetime(b1))
    e = min(pd.to_datetime(a2), pd.to_datetime(b2))
    return (s <= e), s, e

# í™”ë©´ ë²”ìœ„ì™€ ì˜ˆì¸¡ ìŒì˜ êµì§‘í•©
view_start, view_end = df_sel["date"].min(), df_sel["date"].max()
has_fct, fct_s, fct_e = intersect(view_start, view_end, FCT_START, FCT_END)

# ë§ˆìŠ¤í¬
act_mask = df_sel["source"].eq("actual")
fct_mask = df_sel["source"].eq("forecast")

# ì¤‘ì•™ ì¢Œí‘œ (ë°°ê²½ í…ìŠ¤íŠ¸ ìœ„ì¹˜)
prev_mid = prev_start + (prev_end - prev_start) / 2
curr_mid = start_date + (end_date - start_date) / 2

# ìŠ¤íŒ¬ ë¼ë²¨ë§
def label_for_span(s, e):
    has_act_span = not df_sel[(df_sel["date"].between(s, e)) & act_mask].empty
    has_fct_span = not df_sel[(df_sel["date"].between(s, e)) & fct_mask].empty
    if has_act_span and has_fct_span: return "í˜¼í•©"
    if has_act_span: return "ì‹¤ì "
    if has_fct_span: return "ì˜ˆì¸¡"
    return ""

prev_label = label_for_span(prev_start, prev_end)
curr_label = label_for_span(start_date, end_date)   # ì„ íƒê¸°ê°„ì€ ë³´í†µ "ì˜ˆì¸¡"

# === ë°°ê²½: ì˜ˆì¸¡ êµ¬ê°„ë§Œ ì—°íŒŒë‘ ìŒì˜, í…ìŠ¤íŠ¸ëŠ” ê·œì¹™ì— ë§ì¶° í‘œì‹œ ===
shapes, annotations = [], []
if has_fct:
    shapes.append(dict(
        type="rect", xref="x", yref="paper",
        x0=fct_s, x1=fct_e, y0=0, y1=1,
        fillcolor="rgba(30,144,255,0.08)", line=dict(width=0), layer="below"
    ))

# ìš”ì²­ ê·œì¹™: 'ì´ì „ê¸°ê°„,í˜¼í•©'ì€ 'ì‹¤ì ' ë¬¸êµ¬ / 'ì„ íƒê¸°ê°„,ì˜ˆì¸¡'ì€ 'ì˜ˆì¸¡' ë¬¸êµ¬
prev_text = "ì‹¤ì " if prev_label in ("ì‹¤ì ", "í˜¼í•©") else "ì˜ˆì¸¡"
curr_text = "ì˜ˆì¸¡"

annotations.extend([
    dict(x=prev_mid, y=0.5, xref="x", yref="paper",
         text=prev_text, showarrow=False,
         font=dict(size=28, color="rgba(30,30,30,0.28)"), align="center"),
    dict(x=curr_mid, y=0.5, xref="x", yref="paper",
         text=curr_text, showarrow=False,
         font=dict(size=28, color="rgba(0,91,187,0.38)"), align="center"),
])
fig = go.Figure()
fig.update_layout(shapes=shapes, annotations=annotations)

# === ìƒ‰ìƒ ===
color_sales = "#1f77b4"       # ë§¤ì¶œ(ì„ , y1)
color_pax   = "#ff7f0e"       # ìŠ¹ê°(ë§‰ëŒ€, y2)

# --- ë§‰ëŒ€ ë¨¼ì € ì¶”ê°€(ì‹¤ì  â†’ ì˜ˆì¸¡), ë§ˆì§€ë§‰ì— êº¾ì€ì„  ì¶”ê°€ ---
# ìŠ¹ê°ìˆ˜(ì‹¤ì ): ë§‰ëŒ€ (overlay ì–‡ì•„ì§ ë°©ì§€ â†’ group ëª¨ë“œ ì‚¬ìš©, í­ ìë™ í™•ë³´)
act_plot = df_sel[act_mask]
if not act_plot.empty:
    fig.add_trace(go.Bar(
        x=act_plot["date"], y=act_plot["passengers"],
        name="ìŠ¹ê°ìˆ˜(ì‹¤ì )",
        marker=dict(color=color_pax, line=dict(width=0)),
        opacity=0.55,
        offsetgroup="actual",      # âœ… group ëª¨ë“œì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ê·¸ë£¹
        yaxis="y2",
        hovertemplate="<b>%{x|%Y-%m-%d}</b><br>ìŠ¹ê°ìˆ˜: %{y:,.0f} ëª…<extra></extra>"
    ))

# ìŠ¹ê°ìˆ˜(ì˜ˆì¸¡): ë§‰ëŒ€ (ì‹¤ì ë³´ë‹¤ ë” íˆ¬ëª…)
fct_plot = df_sel[fct_mask]
if not fct_plot.empty:
    fig.add_trace(go.Bar(
        x=fct_plot["date"], y=fct_plot["passengers"],
        name="ìŠ¹ê°ìˆ˜(ì˜ˆì¸¡)",
        marker=dict(
            color=color_pax,
            pattern=dict(shape="/", fgcolor="rgba(0,0,0,0.45)", solidity=0.25),
            line=dict(width=0)
        ),
        opacity=0.38,
        offsetgroup="forecast",    # âœ… group ëª¨ë“œì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ê·¸ë£¹
        yaxis="y2",
        hovertemplate="<b>%{x|%Y-%m-%d}</b><br>ìŠ¹ê°ìˆ˜(ì˜ˆì¸¡): %{y:,.0f} ëª…<extra></extra>"
    ))

# === ë§¤ì¶œì•¡(ë°±ë§Œì›): ì‹¤ì„  + ì˜ˆì¸¡ë§Œ ì ì„  ì˜¤ë²„ë ˆì´ (ëŠê¹€ ì—†ì´ ì´ì–´ì§)
# 1) ì „ì²´ êµ¬ê°„ ì‹¤ì„  (legend: ë§¤ì¶œì•¡(ì‹¤ì ))
fig.add_trace(go.Scatter(
    x=df_sel["date"], y=df_sel["sales_million"],
    name="ë§¤ì¶œì•¡(ì‹¤ì )",
    mode="lines+markers",
    line=dict(color=color_sales, width=2.6, dash="solid"),
    marker=dict(size=6, color=color_sales),
    yaxis="y1",
    connectgaps=True,
    hovertemplate="<b>%{x|%Y-%m-%d}</b><br>ë§¤ì¶œì•¡: %{y:,.1f} ë°±ë§Œì›<extra></extra>"
))

# 2) ì˜ˆì¸¡ êµ¬ê°„ë§Œ ì ì„  ì˜¤ë²„ë ˆì´ (legend: ë§¤ì¶œì•¡(ì˜ˆì¸¡))
sales_million_forecast_only = np.where(fct_mask.to_numpy(), df_sel["sales_million"], None)
fig.add_trace(go.Scatter(
    x=df_sel["date"], y=sales_million_forecast_only,
    name="ë§¤ì¶œì•¡(ì˜ˆì¸¡)",                  # âœ… legend í¬í•¨
    mode="lines",
    line=dict(color=color_sales, width=3.0, dash="dashdot"),  # âœ… ë” ëˆˆì— ë„ëŠ” ì ì„ 
    yaxis="y1",
    connectgaps=True,
    hoverinfo="skip"
))

# === ë ˆì´ì•„ì›ƒ/ì¶•/ë²”ë¡€ ===
fig.update_layout(
    template="plotly_white",
    hovermode="x unified",
    # ğŸ”‘ í•µì‹¬: overlay â†’ group ìœ¼ë¡œ ë³€ê²½í•´ ë§‰ëŒ€ í­ ì •ìƒí™”
    barmode="group",
    bargap=0.15,                 # ë§‰ëŒ€ ê°„ ê°„ê²©(ì‘ì„ìˆ˜ë¡ ë‘êº¼ì›€)
    bargroupgap=0.05,            # ê·¸ë£¹ ê°„ ê°„ê²©
    xaxis=dict(title="", showgrid=True, tickformat="%Y-%m-%d", tickangle=-45),
    yaxis=dict(title="ë§¤ì¶œì•¡(ë°±ë§Œì›)", tickformat=",.1f", showgrid=True, zeroline=False),
    yaxis2=dict(title="ìŠ¹ê°ìˆ˜", overlaying="y", side="right", tickformat=",.0f", showgrid=False, zeroline=False),
    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1.0, bgcolor="rgba(255,255,255,0.7)"),
    margin=dict(t=60, r=50, b=60, l=70),
    font=dict(family="Nanum Gothic, Malgun Gothic, AppleGothic, Noto Sans KR, Sans-Serif", size=13)
)

config = dict(
    displaylogo=False,
    toImageButtonOptions=dict(format="png", filename=f"dual_axis_{start_date.date()}_{end_date.date()}", scale=2),
    modeBarButtonsToAdd=["hovercompare"]
)
st.plotly_chart(fig, use_container_width=True, config=config)

# ================= ìš”ì•½í‘œ =================
def agg_period_sum(df: pd.DataFrame, period_label: str, col: str):
    return pd.to_numeric(
        df.loc[df["period"].eq(period_label), col],
        errors="coerce"
    ).fillna(0).sum()

# df_selì—ëŠ” ì´ë¯¸ ì˜ˆì¸¡ ë§¤ì¶œì´ ì£¼ì…ë˜ì–´ ìˆìŒ (sales_amount = ì‹¤ì  + ì˜ˆì¸¡ê°’ ì£¼ì…)
prev_sales_m = agg_period_sum(df_sel, "ì´ì „ê¸°ê°„", "sales_amount") / 1_000_000
curr_sales_m = agg_period_sum(df_sel, "ì„ íƒê¸°ê°„", "sales_amount") / 1_000_000
prev_pax     = agg_period_sum(df_sel, "ì´ì „ê¸°ê°„", "passengers")
curr_pax     = agg_period_sum(df_sel, "ì„ íƒê¸°ê°„", "passengers")

def pct_change(new, old):
    return np.nan if old == 0 else (new - old) / old * 100.0

sales_pct, pax_pct = pct_change(curr_sales_m, prev_sales_m), pct_change(curr_pax, prev_pax)

summary_df = pd.DataFrame({
    "ì´ì „ê¸°ê°„ í•©ê³„": [prev_sales_m, prev_pax],
    "ì„ íƒê¸°ê°„ í•©ê³„": [curr_sales_m, curr_pax],
    "ì¦ê°ìœ¨(%)": [sales_pct, pax_pct],
}, index=["ë§¤ì¶œì•¡(ë°±ë§Œì›)", "ìŠ¹ê°ìˆ˜(ëª…)"])

idx = pd.IndexSlice
def style_delta(v):
    if pd.isna(v):
        return ""
    return "color: green; font-weight:700;" if v >= 0 else "color: red; font-weight:700;"

# ================= ìš”ì•½í‘œ í—¤ë” + ì²´í¬ë°•ìŠ¤ =================
left_col, right_col = st.columns([0.85, 0.15])
with left_col:
    st.markdown("#### ìš”ì•½í‘œ")
with right_col:
    show_detail = st.checkbox("ìì„¸íˆ ë³´ê¸°", value=False)

st.caption(
    f"ì„ íƒê¸°ê°„: {start_date.date()} ~ {end_date.date()}  Â·  ì´ì „ê¸°ê°„: {prev_start.date()} ~ {prev_end.date()}  "
    f"(ì´ì „ê¸°ê°„ ë¼ë²¨: {label_for_span(prev_start, prev_end)} / ì„ íƒê¸°ê°„ ë¼ë²¨: {label_for_span(start_date, end_date)})"
)

# ================= ìš”ì•½í‘œ ë³¸í‘œ =================
styler = (
    summary_df.style
        .format(na_rep="-")
        .format("{:,.1f}", subset=idx["ë§¤ì¶œì•¡(ë°±ë§Œì›)", ["ì´ì „ê¸°ê°„ í•©ê³„", "ì„ íƒê¸°ê°„ í•©ê³„"]])
        .format("{:,.0f}", subset=idx["ìŠ¹ê°ìˆ˜(ëª…)", ["ì´ì „ê¸°ê°„ í•©ê³„", "ì„ íƒê¸°ê°„ í•©ê³„"]])
        .format("{:,.1f}%", subset=idx[:, ["ì¦ê°ìœ¨(%)"]])
        .applymap(style_delta, subset=idx[:, ["ì¦ê°ìœ¨(%)"]])
)
st.dataframe(styler, use_container_width=True)

# ================= ìì„¸íˆ ë³´ê¸°: ì¼ì¼ë°ì´í„°(ì‹¤ì /ì˜ˆì¸¡ + ì˜¤ì°¨ìœ¨) =================
if show_detail:
    # ì„ íƒê¸°ê°„ ë‹¬ë ¥(ëª¨ë“  ì¼ì)
    dates_df = pd.DataFrame({"date": pd.date_range(start_date, end_date, freq="D")})
    if dates_df.empty:
        st.info("ì„ íƒê¸°ê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # 1) ì˜ˆì¸¡ ìŠ¹ê°ìˆ˜: forecast_pass.csv
        f_pass = (
            forecast_df_all[forecast_df_all["date"].between(start_date, end_date)]
            .loc[:, ["date", "passengers"]]
            .rename(columns={"passengers": "pred_passengers"})
        )

        # 2) ì˜ˆì¸¡ ë§¤ì¶œì•¡: forecast_sales.csv / .cvs
        try:
            f_sales_raw = load_forecast_sales_df()
            f_sales = (
                f_sales_raw[f_sales_raw["date"].between(start_date, end_date)]
                .copy()
            )
            f_sales["pred_sales_million"] = (
                pd.to_numeric(f_sales["pred_sales_amount"], errors="coerce") / 1_000_000
            )
            f_sales = f_sales[["date", "pred_sales_million"]]
        except FileNotFoundError as e:
            st.error(f"{e}")
            f_sales = pd.DataFrame(columns=["date", "pred_sales_million"])

        # 3) ì‹¤ì (ìŠ¹ê°/ë§¤ì¶œ): train_reservations_rows.csv
        try:
            act_daily_raw = load_actual_rows_df()
            act_daily = act_daily_raw[
                act_daily_raw["date"].between(start_date, end_date)
            ].copy()
            act_daily.rename(
                columns={
                    "passengers": "act_passengers",
                    "sales_amount": "act_sales_amount",
                },
                inplace=True,
            )
            act_daily["act_sales_million"] = (
                pd.to_numeric(act_daily["act_sales_amount"], errors="coerce") / 1_000_000
            )
            act_daily = act_daily[["date", "act_passengers", "act_sales_million"]]
        except (FileNotFoundError, KeyError) as e:
            st.error(f"ì‹¤ì  ë¡œë”© ì˜¤ë¥˜: {e}")
            act_daily = pd.DataFrame(columns=["date", "act_passengers", "act_sales_million"])

        # 4) ë³‘í•© (ë‹¬ë ¥ ê¸°ì¤€ ì¢Œì¸¡ ì¡°ì¸)
        daily_merged = (
            dates_df.merge(act_daily, on="date", how="left")
                    .merge(f_pass, on="date", how="left")
                    .merge(f_sales, on="date", how="left")
                    .sort_values("date")
        )

        # 5) ì˜¤ì°¨ìœ¨ ê³„ì‚° (ì‹¤ì ì´ 0/ê²°ì¸¡ì´ë©´ NaN)
        daily_merged["ìŠ¹ê°ìˆ˜ ì˜¤ì°¨ìœ¨(%)"] = (
            (daily_merged["pred_passengers"] - daily_merged["act_passengers"])
            / daily_merged["act_passengers"] * 100.0
        ).where(daily_merged["act_passengers"].fillna(0).ne(0))

        daily_merged["ë§¤ì¶œì•¡ ì˜¤ì°¨ìœ¨(%)"] = (
            (daily_merged["pred_sales_million"] - daily_merged["act_sales_million"])
            / daily_merged["act_sales_million"] * 100.0
        ).where(daily_merged["act_sales_million"].fillna(0).ne(0))

        # 6) í‘œ ìƒì„±
        detail_df = pd.DataFrame({
            "ë‚ ì§œ": daily_merged["date"].dt.strftime("%Y-%m-%d"),
            "ì‹¤ì  ìŠ¹ê°ìˆ˜(ëª…)": daily_merged["act_passengers"],
            "ì‹¤ì  ë§¤ì¶œì•¡(ë°±ë§Œì›)": daily_merged["act_sales_million"],
            "ì˜ˆì¸¡ ìŠ¹ê°ìˆ˜(ëª…)": daily_merged["pred_passengers"],
            "ì˜ˆì¸¡ ë§¤ì¶œì•¡(ë°±ë§Œì›)": daily_merged["pred_sales_million"],
            "ìŠ¹ê°ìˆ˜ ì˜¤ì°¨ìœ¨(%)": daily_merged["ìŠ¹ê°ìˆ˜ ì˜¤ì°¨ìœ¨(%)"],
            "ë§¤ì¶œì•¡ ì˜¤ì°¨ìœ¨(%)": daily_merged["ë§¤ì¶œì•¡ ì˜¤ì°¨ìœ¨(%)"],
        })

        # ===== ê°•ì¡° ìŠ¤íƒ€ì¼ í•¨ìˆ˜ ì •ì˜ =====
        def highlight_error(v):
            if pd.isna(v):
                return ""
            if abs(v) <= 10:   # Â±10% ì´ë‚´ëŠ” íŒŒë€ìƒ‰
                return "color: blue; font-weight: 700;"
            elif abs(v) >= 20: # Â±20% ì´ìƒì€ ë¹¨ê°„ìƒ‰
                return "color: red; font-weight: 700;"
            else:
                return ""

        # ===== ìŠ¤íƒ€ì¼ ì ìš© =====
        st.markdown("##### ğŸ“… ì„ íƒê¸°ê°„ ì¼ì¼ ë°ì´í„° (ì‹¤ì  vs ì˜ˆì¸¡ + ì˜¤ì°¨ìœ¨)")
        st.dataframe(
            detail_df.style
                .format({
                    "ì‹¤ì  ìŠ¹ê°ìˆ˜(ëª…)": "{:,.0f}",
                    "ì˜ˆì¸¡ ìŠ¹ê°ìˆ˜(ëª…)": "{:,.0f}",
                    "ì‹¤ì  ë§¤ì¶œì•¡(ë°±ë§Œì›)": "{:,.1f}",
                    "ì˜ˆì¸¡ ë§¤ì¶œì•¡(ë°±ë§Œì›)": "{:,.1f}",
                    "ìŠ¹ê°ìˆ˜ ì˜¤ì°¨ìœ¨(%)": "{:,.1f}%",
                    "ë§¤ì¶œì•¡ ì˜¤ì°¨ìœ¨(%)": "{:,.1f}%"
                })
                .applymap(highlight_error, subset=["ìŠ¹ê°ìˆ˜ ì˜¤ì°¨ìœ¨(%)", "ë§¤ì¶œì•¡ ì˜¤ì°¨ìœ¨(%)"]),  # âœ… ì˜¤ì°¨ìœ¨ ê°•ì¡° ì ìš©
            use_container_width=True,
            height=360
        )
