# app.py â”€â”€ Streamlit (https://<YOUR-APP>.streamlit.app)

import io
from pathlib import Path
from datetime import date, timedelta
import pandas as pd
import numpy as np
import streamlit as st
import plotly.graph_objects as go
import re

# âœ… Ag-Grid (í•©ê³„í–‰ ìƒë‹¨ ê³ ì • & ì»¬ëŸ¼ í•„í„°/ì •ë ¬/ì„ íƒ ì§€ì›)
try:
    from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, JsCode
except Exception as _e:
    AgGrid = None

# ================= ê¸°ë³¸ ì„¤ì • =================
st.set_page_config(page_title="Passengers & Sales (Dual Axis)", layout="wide")

# ======= ìƒë‹¨ íƒ€ì´í‹€ + ë‹¤í¬ëª¨ë“œ í† ê¸€ =======
title_col, theme_col = st.columns([1,0.18])
with title_col:
    st.title("ğŸ“ˆ ì™¸ë¶€ìš”ì¸ ê¸°ë°˜ ì² ë„ìˆ˜ìš”ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
with theme_col:
    DARK = st.checkbox("ğŸŒ™ ë‹¤í¬ ëª¨ë“œ", value=False)

# ---------- í…Œë§ˆ ìƒ‰ìƒ ë³€ìˆ˜ ----------
if DARK:
    BG        = "#0B1220"; SURFACE="#111827"; PANEL_BG="#0F172A"; BORDER="#1F2937"
    TEXT      = "#E5E7EB"; SUBTEXT="#9CA3AF"; SHADOW="rgba(0,0,0,0.35)"
    HILITE1   = "rgba(56,189,248,0.12)"; HILITE2="rgba(148,163,184,0.10)"
    CARD_BG   = "#111827"; CARD_BORDER="#374151"; PLOTLY_TEMPLATE="plotly_dark"
    SUM_BG    = "rgba(56,189,248,0.10)"
else:
    BG        = "#FFFFFF"; SURFACE="#FFFFFF"; PANEL_BG="#F8FAFC"; BORDER="#E5E7EB"
    TEXT      = "#111827"; SUBTEXT="#6B7280"; SHADOW="rgba(0,0,0,0.05)"
    HILITE1   = "rgba(30,144,255,0.08)"; HILITE2="rgba(100,116,139,0.06)"
    CARD_BG   = "#FFFFFF"; CARD_BORDER="#E5E7EB"; PLOTLY_TEMPLATE="plotly_white"
    SUM_BG    = "rgba(30,144,255,0.08)"

# ---- ê¸€ë¡œë²Œ ìŠ¤íƒ€ì¼ ----
st.markdown(
    f"""
    <style>
    html, body, .stApp {{ background: {BG}; color:{TEXT}; }}
    .panel {{
        border: 1px solid {BORDER};
        background: {PANEL_BG};
        border-radius: 12px;
        padding: 12px 14px;
        box-shadow: 0 4px 18px {SHADOW};
        margin-bottom: 12px;
    }}
    .lg-line   {{ height:2px; border-top: 4px solid #1f77b4; border-radius:2px; display:inline-block; width:22px; margin-right:6px; }}
    .lg-line-dash {{
        height:0; display:inline-block; width:22px; margin-right:6px; position:relative; top:2px;
        border-top: 0; background: repeating-linear-gradient(90deg, #1f77b4 0 6px, rgba(0,0,0,0) 6px 12px);
    }}
    .lg-bar    {{ background:#ff7f0e; display:inline-block; width:12px; height:12px; border-radius:2px; margin-right:6px; }}
    .lg-bar-f  {{ background:#ff7f0e; opacity:0.7; display:inline-block; width:12px; height:12px; border-radius:2px; margin-right:6px; }}
    .lg-text   {{ font-size: 13px; color:{TEXT}; vertical-align:middle; }}
    .legend-row {{ display:flex; gap:18px; align-items:center; flex-wrap:wrap; justify-content:flex-end; }}
    div[data-testid="stDataFrame"] div[role="grid"] {{ background: {SURFACE}; }}
    </style>
    """,
    unsafe_allow_html=True,
)

# ===== ê¸°ê°„ ì •ì˜ =====
ACT_START = pd.to_datetime("2020-08-01")
ACT_END   = pd.to_datetime("2025-08-31")  # âœ… ì‹¤ì  ì¢…ë£Œ
FCT_START = pd.to_datetime("2025-09-01")
FCT_END   = pd.to_datetime("2025-11-29")

# ================= íŒŒì¼ ë¡œë” =================
@st.cache_data(show_spinner=False)
def load_df_from_repo_csv(filename: str):
    path = Path(filename)
    if not path.exists():
        raise FileNotFoundError(f"'{filename}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    for enc in ("utf-8-sig", "cp949"):
        try:
            return pd.read_csv(path, encoding=enc)
        except Exception:
            continue
    return pd.read_csv(path)

# ================= íœ´ì¼ ë¡œë” =================
@st.cache_data(show_spinner=False)
def load_holidays_df() -> pd.DataFrame:
    try:
        df = load_df_from_repo_csv("holidays_rows.csv").copy()
    except FileNotFoundError:
        st.warning("'holidays_rows.csv' íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. íœ´ë¬´ í‘œì‹œëŠ” ìƒëµë©ë‹ˆë‹¤.")
        return pd.DataFrame(columns=["holiday_date","name"])
    if "holiday_date" not in df.columns:
        st.warning("'holidays_rows.csv'ì— 'holiday_date' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. íœ´ë¬´ í‘œì‹œëŠ” ìƒëµë©ë‹ˆë‹¤.")
        return pd.DataFrame(columns=["holiday_date","name"])
    if "name" not in df.columns:
        df["name"] = ""
    df["holiday_date"] = pd.to_datetime(df["holiday_date"], errors="coerce").dt.normalize()
    df = df.dropna(subset=["holiday_date"]).drop_duplicates(subset=["holiday_date"]).sort_values("holiday_date")
    return df[["holiday_date","name"]]

# ================= ì‹¤ì  / ì˜ˆì¸¡ ë¡œë” =================
@st.cache_data(show_spinner=False)
def load_actual_df() -> pd.DataFrame:
    df = load_df_from_repo_csv("merged.csv").copy()
    cols = {c.lower(): c for c in df.columns}
    df.rename(columns={cols.get("date","date"):"date",
                       cols.get("passengers","passengers"):"passengers",
                       cols.get("sales_amount","sales_amount"):"sales_amount"}, inplace=True)
    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    df = df.dropna(subset=["date"]).sort_values("date")
    df = df[(df["date"] >= ACT_START) & (df["date"] <= ACT_END)]
    df["passengers"] = pd.to_numeric(df["passengers"], errors="coerce")
    df["sales_amount"] = pd.to_numeric(df["sales_amount"], errors="coerce")
    return df

@st.cache_data(show_spinner=False)
def load_forecast_df() -> pd.DataFrame:
    f = load_df_from_repo_csv("forecast_pass.csv").copy()
    cols = {c.lower(): c for c in f.columns}
    f.rename(columns={cols.get("date","date"):"date",
                      cols.get("forecast_90d","forecast_90d"):"passengers"}, inplace=True)
    f["date"] = pd.to_datetime(f["date"], errors="coerce")
    f = f.dropna(subset=["date"]).sort_values("date")
    f = f[(f["date"] >= FCT_START) & (f["date"] <= FCT_END)]
    f["passengers"] = pd.to_numeric(f["passengers"], errors="coerce")
    f["sales_amount"] = np.nan
    return f

@st.cache_data(show_spinner=False)
def load_forecast_sales_df() -> pd.DataFrame:
    f = load_df_from_repo_csv("forecast_sales.csv").copy()
    cols = {c.lower(): c for c in f.columns}
    f.rename(columns={cols.get("date","date"):"date",
                      cols.get("forecast_90d","forecast_90d"):"pred_sales_amount"}, inplace=True)
    f["date"] = pd.to_datetime(f["date"], errors="coerce")
    f = f.dropna(subset=["date"]).sort_values("date")
    f = f[(f["date"] >= FCT_START) & (f["date"] <= FCT_END)]
    f["pred_sales_amount"] = pd.to_numeric(f["pred_sales_amount"], errors="coerce")
    return f[["date","pred_sales_amount"]]

@st.cache_data(show_spinner=False)
def load_actual_rows_df() -> pd.DataFrame:
    df = load_df_from_repo_csv("train_reservations_rows.csv").copy()
    required = ["travel_date","passengers","sales_amount"]
    miss = [c for c in required if c not in df.columns]
    if miss: raise KeyError(f"'train_reservations_rows.csv'ì— ë‹¤ìŒ ì»¬ëŸ¼ í•„ìš”: {', '.join(miss)}")
    df["travel_date"] = pd.to_datetime(df["travel_date"], errors="coerce")
    df = df.dropna(subset=["travel_date"])
    for c in ["passengers","sales_amount"]:
        df[c] = df[c].astype(str).str.replace(",", "", regex=False).replace("nan", np.nan)
        df[c] = pd.to_numeric(df[c], errors="coerce")
    daily = (df.assign(date=df["travel_date"].dt.floor("D"))
               .groupby("date", as_index=False)[["passengers","sales_amount"]].sum()
               .sort_values("date"))
    daily = daily[(daily["date"] >= ACT_START) & (daily["date"] <= ACT_END)]
    return daily

# ================= ìœ í‹¸ =================
KO_DAYS = ["ì›”","í™”","ìˆ˜","ëª©","ê¸ˆ","í† ","ì¼"]
def fmt_date_ko(s: pd.Series) -> pd.Series:
    return s.dt.strftime("%Y-%m-%d") + " (" + s.dt.weekday.map(dict(enumerate(KO_DAYS))) + ")"

def ensure_in_range(s: pd.Timestamp, e: pd.Timestamp, lo: pd.Timestamp, hi: pd.Timestamp):
    s2 = max(s, lo); e2 = min(e, hi)
    if s2 > e2: s2, e2 = lo, lo
    return s2, e2

def align_last_year_same_weekday(r_s: pd.Timestamp, n_days: int):
    raw = (r_s - pd.DateOffset(years=1)).normalize()
    diff = (r_s.weekday() - raw.weekday()) % 7
    l_s = raw + pd.Timedelta(days=diff)
    l_e = l_s + pd.Timedelta(days=n_days-1)
    l_s, l_e = ensure_in_range(l_s, l_e, ACT_START, ACT_END)
    cur = (l_e - l_s).days + 1
    if cur < n_days:
        deficit = n_days - cur
        l_s = max(ACT_START, l_s - pd.Timedelta(days=deficit))
        l_e = l_s + pd.Timedelta(days=n_days-1)
    return ensure_in_range(l_s, l_e, ACT_START, ACT_END)

def force_same_length(left_s, left_e, right_s, right_e):
    n = (right_e - right_s).days + 1
    left_e_target = left_s + pd.Timedelta(days=n-1)
    left_s2, left_e2 = ensure_in_range(left_s, left_e_target, ACT_START, ACT_END)
    cur = (left_e2 - left_s2).days + 1
    if cur < n:
        deficit = n - cur
        left_s2 = max(ACT_START, left_s2 - pd.Timedelta(days=deficit))
    left_s2, left_e2 = ensure_in_range(left_s2, left_s2 + pd.Timedelta(days=n-1), ACT_START, ACT_END)
    right_s2, right_e2 = ensure_in_range(right_s, right_e, FCT_START, FCT_END)
    return left_s2, left_e2, right_s2, right_e2

# --------- ì™¸ë¶€ìš”ì¸(ì´ë²¤íŠ¸ í•©ê³„) + íœ´ì¼ í”Œë˜ê·¸ ----------
@st.cache_data(show_spinner=False)
def load_external_factors_df() -> pd.DataFrame:
    try:
        df = load_df_from_repo_csv("merged.csv").copy()
    except FileNotFoundError:
        st.warning("'merged.csv' íŒŒì¼ì„ ì°¾ì§€ ëª»í•´ ì´ë²¤íŠ¸ í•©ê³„ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(columns=["date","event_sum"])
    df.columns = [str(c).strip().lower() for c in df.columns]
    if "date" not in df.columns:
        st.warning("'merged.csv'ì— 'date' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(columns=["date","event_sum"])
    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    df = df.dropna(subset=["date"]).sort_values("date")
    event_cols = ["bexco_events_count","coex_events_count","kintex_events_count",
                  "games_baseball","games_soccer","concerts_events_count"]
    for c in event_cols:
        if c not in df.columns: df[c] = 0
        df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0)
    df["event_sum"] = df[event_cols].sum(axis=1)
    df = df[(df["date"] >= ACT_START) & (df["date"] <= ACT_END)]
    return df[["date","event_sum"]]

def build_event_strings(dates_index: pd.DatetimeIndex, factors_df: pd.DataFrame) -> list[str]:
    if dates_index is None or len(dates_index) == 0: return []
    if isinstance(factors_df, pd.DataFrame) and not factors_df.empty and "date" in factors_df.columns:
        f = factors_df.set_index("date").reindex(dates_index)
        ev = pd.to_numeric(f.get("event_sum"), errors="coerce").fillna(0)
    else:
        ev = pd.Series([0]*len(dates_index), index=dates_index)
    return [f"ì´ë²¤íŠ¸ {int(round(v))}" for v in ev]

# === íœ´ì¼ëª… 6ì ë¼ë²¨ + íˆ´íŒ ì „ì²´ëª… ===
def _truncate_with_ellipsis(text: str, max_len: int = 6) -> str:
    if not isinstance(text, str):
        return ""
    return text if len(text) <= max_len else (text[:max_len] + "â€¦")

def build_holiday_labels(dates_index: pd.DatetimeIndex, holidays_df: pd.DataFrame, max_len: int = 6):
    if dates_index is None or len(dates_index) == 0:
        return [], []
    if holidays_df is None or holidays_df.empty or "holiday_date" not in holidays_df.columns:
        return ["" for _ in range(len(dates_index))], ["" for _ in range(len(dates_index))]
    hmap = holidays_df.set_index("holiday_date")["name"]
    labels, fulls = [], []
    for d in dates_index:
        name = hmap.get(d.normalize(), "")
        if isinstance(name, float) and np.isnan(name):
            name = ""
        if name:
            labels.append(_truncate_with_ellipsis(str(name), max_len))
            fulls.append(str(name))
        else:
            labels.append("")
            fulls.append("")
    return labels, fulls

# ===================== ì‚¬ì´ë“œë°”: ê¸°ê°„ ì„ íƒ =====================
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“… ê¸°ê°„ ì„ íƒ")

default_right_start = date(2025, 9, 1)
default_right_end   = date(2025, 9, 7)
right_range = st.session_state.get("right_range", (default_right_start, default_right_end))
right_sel = st.sidebar.date_input("â‘  ì˜ˆì¸¡ ê¸°ê°„ (YYYY-MM-DD)",
    value=right_range, min_value=FCT_START.date(), max_value=FCT_END.date(), key="right_picker_sidebar")

left_mode = st.sidebar.radio("â‘¡ ì‹¤ì  ê¸°ê°„ ëª¨ë“œ",
    options=["ì‚¬ìš© ì•ˆ í•¨ (ì˜ˆì¸¡ë§Œ)", "ì „ë…„ë„ ë™ì¼(ì¼ì)", "ì „ë…„ë„ ë™ì¼(ìš”ì¼)", "ì‚¬ìš©ì ì§€ì •"], index=1, key="left_mode_sidebar")

left_sel = None
if left_mode == "ì‚¬ìš©ì ì§€ì •":
    left_range = st.session_state.get("left_range", (date(2024, 9, 1), date(2024, 9, 7)))
    left_sel = st.sidebar.date_input("ì‹¤ì  ê¸°ê°„ (YYYY-MM-DD)",
        value=left_range, min_value=ACT_START.date(), max_value=ACT_END.date(), key="left_picker_sidebar")

# ================= ê¸°ê°„ ì •ê·œí™”/ë™ê¸°í™” =================
def norm_tuple(sel):
    return sel if isinstance(sel, tuple) else (sel, sel)

r_s, r_e = map(pd.to_datetime, norm_tuple(right_sel))
r_s, r_e = ensure_in_range(r_s, r_e, FCT_START, FCT_END)
N_days = (r_e - r_s).days + 1

if left_mode == "ì‚¬ìš© ì•ˆ í•¨ (ì˜ˆì¸¡ë§Œ)":
    l_s, l_e = None, None
elif left_mode == "ì „ë…„ë„ ë™ì¼(ì¼ì)":
    l_s = (r_s - pd.DateOffset(years=1)).normalize(); l_e = l_s + pd.Timedelta(days=N_days-1)
    l_s, l_e = ensure_in_range(l_s, l_e, ACT_START, ACT_END)
elif left_mode == "ì „ë…„ë„ ë™ì¼(ìš”ì¼)":
    l_s, l_e = align_last_year_same_weekday(r_s, N_days)
else:
    l_s, l_e = map(pd.to_datetime, norm_tuple(left_sel))
    l_s, l_e, r_s, r_e = force_same_length(l_s, l_e, r_s, r_e)

st.session_state["right_range"] = (r_s.date(), r_e.date())
if left_mode == "ì‚¬ìš©ì ì§€ì •" and l_s is not None:
    st.session_state["left_range"] = (l_s.date(), l_e.date())

# ================= ì™¸ë¶€ ë°ì´í„° ë¡œë“œ =================
actual_df_all   = load_actual_df()
forecast_df_all = load_forecast_df()
external_factors_df = load_external_factors_df()
holidays_df = load_holidays_df()

try:
    forecast_sales_all = load_forecast_sales_df()
except FileNotFoundError as e:
    st.warning(f"ì˜ˆì¸¡ ë§¤ì¶œ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")
    forecast_sales_all = pd.DataFrame(columns=["date","pred_sales_amount"])

def get_range(df, s, e, tag):
    if s is None or e is None: return pd.DataFrame(columns=["date","passengers","sales_amount","source"])
    out = df[(df["date"] >= s) & (df["date"] <= e)].copy(); out["source"] = tag; return out

left_df  = get_range(actual_df_all,   l_s, l_e, "actual") if l_s is not None else pd.DataFrame(columns=["date","passengers","sales_amount","source"])
right_df = get_range(forecast_df_all, r_s, r_e, "forecast")

if not right_df.empty:
    right_df = right_df.merge(forecast_sales_all, on="date", how="left")
    right_df["sales_amount"] = np.where(right_df["sales_amount"].isna(), right_df["pred_sales_amount"], right_df["sales_amount"])

df_sel = pd.concat(
    ([left_df.assign(period="ì‹¤ì ê¸°ê°„")] if not left_df.empty else []) + [right_df.assign(period="ì˜ˆì¸¡ê¸°ê°„")],
    ignore_index=True).sort_values("date") if (not right_df.empty or not left_df.empty) else pd.DataFrame(columns=["date","passengers","sales_amount","source","period"])

df_sel["sales_million"] = pd.to_numeric(df_sel["sales_amount"], errors="coerce")/1_000_000
df_sel["passengers_k"]  = pd.to_numeric(df_sel["passengers"], errors="coerce")/1_000

# ================= Xì¶• ì¹´í…Œê³ ë¦¬ =================
order_left  = pd.date_range(l_s, l_e, freq="D") if l_s is not None else pd.DatetimeIndex([])
order_right = pd.date_range(r_s, r_e, freq="D")
category_array = (
    [f"ì‹¤ì |{d.strftime('%Y-%m-%d')}" for d in order_left] +
    [f"ì˜ˆì¸¡|{d.strftime('%Y-%m-%d')}" for d in order_right]
)
if not df_sel.empty:
    df_sel["x_cat"] = df_sel.apply(lambda r: f"{'ì‹¤ì ' if r['period']=='ì‹¤ì ê¸°ê°„' else 'ì˜ˆì¸¡'}|{r['date'].strftime('%Y-%m-%d')}", axis=1)

# =================== ê·¸ë˜í”„ íŒ¨ë„ ===================
st.markdown('<div class="panel">', unsafe_allow_html=True)
st.subheader("ì˜ˆì¸¡ê·¸ë˜í”„")

sp, cSales, cPax = st.columns([8,1.6,1.6])
with cSales: show_sales = st.checkbox("ë§¤ì¶œì•¡", True, key="cb_sales")
with cPax:   show_pax   = st.checkbox("ìŠ¹ê°ìˆ˜", True, key="cb_pax")

st.markdown(
    """
    <div class="legend-row" style="margin-top:4px;">
      <div><span class="lg-line"></span><span class="lg-text">ë§¤ì¶œì•¡(ì‹¤ì )</span></div>
      <div><span class="lg-line-dash"></span><span class="lg-text">ë§¤ì¶œì•¡(ì˜ˆì¸¡)</span></div>
      <div><span class="lg-bar"></span><span class="lg-text">ìŠ¹ê°ìˆ˜(ì‹¤ì )</span></div>
      <div><span class="lg-bar-f"></span><span class="lg-text">ìŠ¹ê°ìˆ˜(ì˜ˆì¸¡)</span></div>
    </div>
    """, unsafe_allow_html=True
)

fig = go.Figure(); color_sales="#1f77b4"; color_pax="#ff7f0e"
shapes = []
if len(order_left)>0:
    shapes.append(dict(type="rect", xref="x", yref="paper", x0=category_array[0], x1=category_array[len(order_left)-1], y0=0, y1=1, fillcolor=HILITE2, line=dict(width=0), layer="below"))
if len(order_right)>0:
    shapes.append(dict(type="rect", xref="x", yref="paper", x0=category_array[len(order_left)], x1=category_array[-1], y0=0, y1=1, fillcolor=HILITE1, line=dict(width=0), layer="below"))

if show_pax and not df_sel.empty:
    act_plot = df_sel[df_sel["source"].eq("actual")]; fct_plot = df_sel[df_sel["source"].eq("forecast")]
    if not act_plot.empty:
        fig.add_trace(go.Bar(x=act_plot["x_cat"], y=act_plot["passengers_k"], name="ìŠ¹ê°ìˆ˜(ì‹¤ì )",
                             marker=dict(color=color_pax, line=dict(width=0)), opacity=0.55, offsetgroup="pax", yaxis="y2",
                             hovertemplate="<b>%{x}</b><br>ìŠ¹ê°ìˆ˜: %{y:,.0f} ì²œëª…<extra></extra>"))
    if not fct_plot.empty:
        fig.add_trace(go.Bar(x=fct_plot["x_cat"], y=fct_plot["passengers_k"], name="ìŠ¹ê°ìˆ˜(ì˜ˆì¸¡)",
                             marker=dict(color=color_pax, pattern=dict(shape="/", fgcolor="rgba(0,0,0,0.45)", solidity=0.40), line=dict(width=0)),
                             opacity=0.38, offsetgroup="pax", yaxis="y2",
                             hovertemplate="<b>%{x}</b><br>ìŠ¹ê°ìˆ˜(ì˜ˆì¸¡): %{y:,.0f} ì²œëª…<extra></extra>"))

if show_sales and not df_sel.empty:
    act_sales = df_sel[df_sel["source"].eq("actual")]; fct_sales = df_sel[df_sel["source"].eq("forecast")]
    if not act_sales.empty:
        fig.add_trace(go.Scatter(x=act_sales["x_cat"], y=act_sales["sales_million"], name="ë§¤ì¶œì•¡(ì‹¤ì )", mode="lines+markers",
                                 line=dict(color=color_sales, width=2.6), marker=dict(size=6, color=color_sales),
                                 yaxis="y1", connectgaps=True,
                                 hovertemplate="<b>%{x}</b><br>ë§¤ì¶œì•¡: %{y:,.0f} ë°±ë§Œì›<extra></extra>"))
    if not fct_sales.empty:
        fig.add_trace(go.Scatter(x=fct_sales["x_cat"], y=fct_sales["sales_million"], name="ë§¤ì¶œì•¡(ì˜ˆì¸¡)", mode="lines",
                                 line=dict(color=color_sales, width=3.5, dash="dash"),
                                 yaxis="y1", connectgaps=True, hoverinfo="skip"))
    if (not act_sales.empty) and (not fct_sales.empty):
        la = act_sales.sort_values("date").iloc[-1]; ff = fct_sales.sort_values("date").iloc[0]
        if pd.notna(la["sales_million"]) and pd.notna(ff["sales_million"]):
            fig.add_trace(go.Scatter(x=[la["x_cat"], ff["x_cat"]], y=[la["sales_million"], ff["sales_million"]],
                                     mode="lines", line=dict(color=color_sales, width=2.0), yaxis="y1",
                                     hoverinfo="skip", showlegend=False))

tickvals, ticktext = [], []
if len(category_array)>0:
    step = max(1, len(category_array)//6)
    for i in range(0, len(category_array), step):
        tickvals.append(category_array[i]); ticktext.append(category_array[i].split("|")[1])
    if category_array[-1] not in tickvals:
        tickvals.append(category_array[-1]); ticktext.append(category_array[-1].split("|")[1])

left_mid_idx = len(order_left)//2 if len(order_left)>0 else None
right_mid_idx= len(order_right)//2 if len(order_right)>0 else None
left_mid_cat = category_array[left_mid_idx] if left_mid_idx is not None else None
right_mid_cat= category_array[(len(order_left)+right_mid_idx)] if right_mid_idx is not None else None

fig.update_layout(template=PLOTLY_TEMPLATE, hovermode="x unified",
    barmode="group", bargap=0.15, bargroupgap=0.05, shapes=shapes,
    xaxis=dict(title="", type="category", categoryorder="array", categoryarray=category_array,
               tickangle=-45, tickmode="array", tickvals=tickvals, ticktext=ticktext, showgrid=True),
    yaxis=dict(title="ë§¤ì¶œì•¡(ë°±ë§Œì›)", tickformat=",.0f", showgrid=True, zeroline=False),
    yaxis2=dict(title="ìŠ¹ê°ìˆ˜(ì²œëª…)", overlaying="y", side="right", tickformat=",.0f", showgrid=False, zeroline=False),
    showlegend=False, margin=dict(t=24, r=50, b=60, l=70),
    font=dict(family="Nanum Gothic, Malgun Gothic, AppleGothic, Noto Sans KR, Sans-Serif", size=13, color=TEXT),
    annotations=[
        *([dict(x=left_mid_cat,  y=0.50, xref="x", yref="paper", text="ì‹¤ì ", showarrow=False, font=dict(size=24, color="#000"), align="center")] if left_mid_cat else []),
        *([dict(x=right_mid_cat, y=0.50, xref="x", yref="paper", text="ì˜ˆì¸¡", showarrow=False, font=dict(size=24, color="#000"), align="center")] if right_mid_cat else []),
    ],
    paper_bgcolor=PANEL_BG, plot_bgcolor=PANEL_BG)

st.plotly_chart(fig, use_container_width=True, config=dict(displaylogo=False,
    toImageButtonOptions=dict(format="png", filename=f"dual_axis_blocks_{date.today()}", scale=2),
    modeBarButtonsToAdd=["hovercompare"]))

if l_s is not None:
    st.caption(f"ì‹¤ì (ì¢Œ): {l_s.date()} ~ {l_e.date()} Â· ì˜ˆì¸¡(ìš°): {r_s.date()} ~ {r_e.date()} Â· ê¸¸ì´ {N_days}ì¼ (ë™ì¼)")
else:
    st.caption(f"ì˜ˆì¸¡ë§Œ í‘œì‹œ: {r_s.date()} ~ {r_e.date()} Â· ê¸¸ì´ {N_days}ì¼")

# ===================== í‘œ(ì‹¤ì /ì˜ˆì¸¡) =====================
left_dates  = pd.date_range(l_s, l_e, freq="D") if l_s is not None else pd.DatetimeIndex([])
right_dates = pd.date_range(r_s, r_e, freq="D")

left_tbl  = pd.DataFrame({"pos": range(len(left_dates)), "date": left_dates}) if len(left_dates)>0 else pd.DataFrame(columns=["pos","date"])
right_tbl = pd.DataFrame({"pos": range(len(right_dates)),"date": right_dates})

# ì™¸ë¶€ìš”ì¸: ì‹¤ì (ì´ë²¤íŠ¸/íœ´ë¬´ì—¬ë¶€ ë¶„ë¦¬), ì˜ˆì¸¡(íœ´ë¬´ì—¬ë¶€)
left_event_strings  = build_event_strings(left_dates, external_factors_df) if len(left_dates)>0 else []

if not left_df.empty:
    l_vals = left_df.set_index("date").reindex(left_dates)
    left_tbl["sales_million"] = (pd.to_numeric(l_vals["sales_amount"], errors="coerce")/1_000_000).values
    left_tbl["passengers_k"]  = (pd.to_numeric(l_vals["passengers"],   errors="coerce")/1_000).values
r_vals = right_df.set_index("date").reindex(right_dates) if not right_df.empty else pd.DataFrame(index=right_dates)
right_tbl["sales_million"] = (pd.to_numeric(r_vals.get("sales_amount"), errors="coerce")/1_000_000).values
right_tbl["passengers_k"]  = (pd.to_numeric(r_vals.get("passengers"),   errors="coerce")/1_000).values

merged_tbl = pd.merge(
    right_tbl,
    left_tbl[["pos","sales_million","passengers_k"]] if not left_tbl.empty else pd.DataFrame(columns=["pos"]),
    on="pos", how="left", suffixes=("_f","_a")
)

for c in ["sales_million_f","sales_million_a","passengers_k_f","passengers_k_a"]:
    merged_tbl[c] = pd.to_numeric(merged_tbl.get(c), errors="coerce")

old_sales = merged_tbl["sales_million_a"]; new_sales = merged_tbl["sales_million_f"]
merged_tbl["sales_pct"] = np.where((old_sales.isna()) | (old_sales==0), np.nan, (new_sales-old_sales)/old_sales*100.0)
old_pax = merged_tbl["passengers_k_a"]; new_pax = merged_tbl["passengers_k_f"]
merged_tbl["pax_pct"] = np.where((old_pax.isna()) | (old_pax==0), np.nan, (new_pax-old_pax)/old_pax*100.0)

# === íœ´ì¼ ë¼ë²¨/íˆ´íŒ (ì‹¤ì /ì˜ˆì¸¡ ëª¨ë‘ ìƒì„±)
left_holiday_labels, left_holiday_fulls = ([], [])
right_holiday_labels, right_holiday_fulls = ([], [])
if len(left_dates) > 0:
    left_holiday_labels, left_holiday_fulls = build_holiday_labels(left_dates, holidays_df, max_len=6)
right_holiday_labels, right_holiday_fulls = build_holiday_labels(right_dates, holidays_df, max_len=6)

# ---- í‘œ ë°ì´í„° êµ¬ì„± ----
actual_df_show = pd.DataFrame()
if not left_tbl.empty:
    d = {
        "ì‹¤ì |ì¼ì": fmt_date_ko(left_tbl["date"]),
        "ì‹¤ì |ë§¤ì¶œì•¡(ë°±ë§Œì›)": left_tbl["sales_million"].round(0).astype("Int64") if st.session_state.get("cb_sales", True) else pd.NA,
        "ì‹¤ì |ìŠ¹ê°ìˆ˜(ì²œëª…)" : left_tbl["passengers_k"].round(0).astype("Int64") if st.session_state.get("cb_pax", True) else pd.NA,
        "ì‹¤ì |ì™¸ë¶€ìš”ì¸"     : left_event_strings,  # â† í´ë¦­ ëŒ€ìƒ (ì´ë²¤íŠ¸ N)
        "ì‹¤ì |íœ´ë¬´ì—¬ë¶€"     : left_holiday_labels,
        "ì‹¤ì |íœ´ì¼ëª…(í’€)"   : left_holiday_fulls,
    }
    actual_df_show = pd.DataFrame({k:v for k,v in d.items()
                                   if not (isinstance(v, pd.Series) and v.isna().all())})


fcast_dict = {
    "ì˜ˆì¸¡|ì¼ì": fmt_date_ko(right_tbl["date"]),
}
if st.session_state.get("cb_sales", True):
    fcast_dict["ì˜ˆì¸¡|ë§¤ì¶œì•¡(ë°±ë§Œì›(Î”))"] = [
        f"{int(round(v if not pd.isna(v) else 0)):,.0f}" + (f" ({'â–²' if (not pd.isna(p) and p>=0) else ('â–¼' if not pd.isna(p) else '')}{'' if pd.isna(p) else f'{abs(p):.1f}%'} )" if not pd.isna(p) else "")
        for v,p in zip(right_tbl["sales_million"], merged_tbl["sales_pct"])
    ]
if st.session_state.get("cb_pax", True):
    fcast_dict["ì˜ˆì¸¡|ìŠ¹ê°ìˆ˜(ì²œëª…(Î”))"] = [
        f"{int(round(v if not pd.isna(v) else 0)):,.0f}" + (f" ({'â–²' if (not pd.isna(p) and p>=0) else ('â–¼' if not pd.isna(p) else '')}{'' if pd.isna(p) else f'{abs(p):.1f}%'} )" if not pd.isna(p) else "")
        for v,p in zip(right_tbl["passengers_k"], merged_tbl["pax_pct"])
    ]
fcast_dict["ì˜ˆì¸¡|íœ´ë¬´ì—¬ë¶€"]   = right_holiday_labels
fcast_dict["ì˜ˆì¸¡|íœ´ì¼ëª…(í’€)"] = right_holiday_fulls

forecast_df_show = pd.DataFrame(fcast_dict)

# í•©ì¹˜ê¸°
if not actual_df_show.empty:
    table_df = pd.concat([actual_df_show, forecast_df_show], axis=1)
else:
    table_df = forecast_df_show.copy()

# í•©ê³„í–‰(ì²« í–‰)
left_sales_m   = int(round(left_tbl["sales_million"].sum())) if "sales_million" in left_tbl.columns else 0
left_pax_k     = int(round(left_tbl["passengers_k"].sum()))   if "passengers_k"  in left_tbl.columns else 0
right_sales_m2 = int(round(right_tbl["sales_million"].sum())) if "sales_million" in right_tbl.columns else 0
right_pax_k2   = int(round(right_tbl["passengers_k"].sum()))  if "passengers_k"  in right_tbl.columns else 0

def top_delta_str(val, base):
    if base is None or base == 0 or val is None: return ""
    delta = (val - base) / base * 100.0; arrow = "â–²" if delta >= 0 else "â–¼"
    return f" ({arrow}{abs(delta):.1f}%)"

sum_row = {}
# ì‹¤ì  í•©ê³„
if "ì‹¤ì |ì¼ì" in table_df.columns: sum_row["ì‹¤ì |ì¼ì"] = "í•©ê³„"
if "ì‹¤ì |ë§¤ì¶œì•¡(ë°±ë§Œì›)" in table_df.columns: sum_row["ì‹¤ì |ë§¤ì¶œì•¡(ë°±ë§Œì›)"] = left_sales_m
if "ì‹¤ì |ìŠ¹ê°ìˆ˜(ì²œëª…)"  in table_df.columns: sum_row["ì‹¤ì |ìŠ¹ê°ìˆ˜(ì²œëª…)"]  = left_pax_k
if "ì‹¤ì |ì™¸ë¶€ìš”ì¸"      in table_df.columns: sum_row["ì‹¤ì |ì™¸ë¶€ìš”ì¸"]      = ""
if "ì‹¤ì |íœ´ë¬´ì—¬ë¶€"      in table_df.columns: sum_row["ì‹¤ì |íœ´ë¬´ì—¬ë¶€"]      = ""
if "ì‹¤ì |íœ´ì¼ëª…(í’€)"    in table_df.columns: sum_row["ì‹¤ì |íœ´ì¼ëª…(í’€)"]    = ""
# ì˜ˆì¸¡ í•©ê³„
if "ì˜ˆì¸¡|ì¼ì" in table_df.columns: sum_row["ì˜ˆì¸¡|ì¼ì"] = "í•©ê³„"
if "ì˜ˆì¸¡|ë§¤ì¶œì•¡(ë°±ë§Œì›(Î”))" in table_df.columns:
    sum_row["ì˜ˆì¸¡|ë§¤ì¶œì•¡(ë°±ë§Œì›(Î”))"] = f"{right_sales_m2:,.0f}{top_delta_str(right_sales_m2, left_sales_m if left_sales_m>0 else None)}"
if "ì˜ˆì¸¡|ìŠ¹ê°ìˆ˜(ì²œëª…(Î”))" in table_df.columns:
    sum_row["ì˜ˆì¸¡|ìŠ¹ê°ìˆ˜(ì²œëª…(Î”))"]   = f"{right_pax_k2:,.0f}{top_delta_str(right_pax_k2, left_pax_k if left_pax_k>0 else None)}"
if "ì˜ˆì¸¡|íœ´ë¬´ì—¬ë¶€" in table_df.columns: sum_row["ì˜ˆì¸¡|íœ´ë¬´ì—¬ë¶€"] = ""
if "ì˜ˆì¸¡|íœ´ì¼ëª…(í’€)" in table_df.columns: sum_row["ì˜ˆì¸¡|íœ´ì¼ëª…(í’€)"] = ""

# ======== ë§¤íŠ¸ë¦­ìŠ¤ ë Œë”ë§ (ì‹¤ì /ì˜ˆì¸¡ ë¶„ë¦¬) ========
# ======== ë§¤íŠ¸ë¦­ìŠ¤(ìƒì„± â†’ ì „ì¹˜) : í–‰=ì¼ì, ì—´=ì§€í‘œ ========
# ======== ë§¤íŠ¸ë¦­ìŠ¤(ìƒì„± â†’ ì „ì¹˜) : í–‰=ì¼ì, ì—´=ì§€í‘œ ========
st.markdown("#### ğŸ“‹ ë°ì´í„° ë§¤íŠ¸ë¦­ìŠ¤ (í–‰=ì¼ì, ì—´=ì§€í‘œ)")

# ---- ì‹¤ì  ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ----
def _build_left_matrix() -> pd.DataFrame:
    if left_tbl.empty:
        return pd.DataFrame()
    rows = {}
    if st.session_state.get("cb_sales", True) and "sales_million" in left_tbl:
        rows["ë§¤ì¶œì•¡(ë°±ë§Œì›)|ì‹¤ì "] = left_tbl["sales_million"].round(0).astype("Int64").tolist()
    if st.session_state.get("cb_pax", True) and "passengers_k" in left_tbl:
        rows["ìŠ¹ê°ìˆ˜(ì²œëª…)|ì‹¤ì "] = left_tbl["passengers_k"].round(0).astype("Int64").tolist()

    df = pd.DataFrame.from_dict(rows, orient="index", columns=fmt_date_ko(left_tbl["date"]))

    # í•©ê³„(ìˆ«ì í–‰ë§Œ)
    sums = []
    for idx in df.index:
        s = pd.to_numeric(df.loc[idx], errors="coerce").sum(min_count=1)
        sums.append("" if pd.isna(s) else int(round(s)))
    df.insert(0, "í•©ê³„", sums)
    return df

# ---- ì˜ˆì¸¡ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ----
def _build_right_matrix() -> pd.DataFrame:
    if right_tbl.empty:
        return pd.DataFrame()

    def _delta_str(pct):
        if pd.isna(pct): return ""
        return f" ({'â–²' if pct>=0 else 'â–¼'}{abs(pct):.1f}%)"

    rows = {}
    if st.session_state.get("cb_sales", True) and "sales_million" in right_tbl:
        vals = right_tbl["sales_million"]
        pcts = merged_tbl["sales_pct"] if "sales_pct" in merged_tbl.columns else pd.Series([pd.NA]*len(vals))
        rows["ë§¤ì¶œì•¡(ë°±ë§Œì›)|ì˜ˆì¸¡(Î”)"] = [
            ("" if pd.isna(v) else f"{int(round(v)):,.0f}") + _delta_str(p)
            for v, p in zip(vals, pcts)
        ]
    if st.session_state.get("cb_pax", True) and "passengers_k" in right_tbl:
        vals = right_tbl["passengers_k"]
        pcts = merged_tbl["pax_pct"] if "pax_pct" in merged_tbl.columns else pd.Series([pd.NA]*len(vals))
        rows["ìŠ¹ê°ìˆ˜(ì²œëª…)|ì˜ˆì¸¡(Î”)"] = [
            ("" if pd.isna(v) else f"{int(round(v)):,.0f}") + _delta_str(p)
            for v, p in zip(vals, pcts)
        ]
    df = pd.DataFrame.from_dict(rows, orient="index", columns=fmt_date_ko(right_tbl["date"]))
    # í•©ê³„
    sum_col = []
    for idx in df.index:
        if idx.startswith("ë§¤ì¶œì•¡"):
            s = pd.to_numeric(right_tbl.get("sales_million"), errors="coerce").sum(min_count=1)
            sum_col.append("" if pd.isna(s) else f"{int(round(s)):,.0f}")
        elif idx.startswith("ìŠ¹ê°ìˆ˜"):
            s = pd.to_numeric(right_tbl.get("passengers_k"), errors="coerce").sum(min_count=1)
            sum_col.append("" if pd.isna(s) else f"{int(round(s)):,.0f}")
        else:
            sum_col.append("")
    df.insert(0, "í•©ê³„", sum_col)
    return df

left_matrix  = _build_left_matrix()
right_matrix = _build_right_matrix()

# ---- ì „ì¹˜ ----
def _transpose_with_sum_first(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty: return pd.DataFrame()
    t = df.T
    if "í•©ê³„" in t.index:
        t = pd.concat([t.loc[["í•©ê³„"]], t.drop(index=["í•©ê³„"])], axis=0)
    return t

left_T  = _transpose_with_sum_first(left_matrix)
right_T = _transpose_with_sum_first(right_matrix)

# ==== [ì‹¤ì ê¸°ê°„(ì „ì¹˜)] ì»¬ëŸ¼ ìˆœì„œ: 'íœ´ì¼' â†’ 'ì™¸ë¶€ìš”ì¸' ë¡œ ë§¨ ëì— ì •ë ¬ + ìˆ«ì 3ìë¦¬ ì½¤ë§ˆ ====
if not left_T.empty:
    # 1) ë§¨ ì˜¤ë¥¸ìª½ì— 'íœ´ì¼' ê·¸ë‹¤ìŒ 'ì™¸ë¶€ìš”ì¸' ìˆœì„œë¡œ ì¬ë°°ì¹˜
    if "íœ´ì¼" in left_T.columns:
        _col = left_T.pop("íœ´ì¼")
        left_T["íœ´ì¼"] = _col
    if "ì™¸ë¶€ìš”ì¸" in left_T.columns:
        _col = left_T.pop("ì™¸ë¶€ìš”ì¸")
        left_T["ì™¸ë¶€ìš”ì¸"] = _col

    # 2) ë§¤ì¶œì•¡/ìŠ¹ê°ìˆ˜ëŠ” 3ìë¦¬ ì½¤ë§ˆë¡œ í¬ë§· (í•©ê³„ í–‰ í¬í•¨)
    def _fmt_commas(v):
        if v is None or (isinstance(v, float) and pd.isna(v)) or (isinstance(v, str) and v.strip() == ""):
            return ""
        try:
            n = pd.to_numeric(v, errors="coerce")
            if pd.isna(n):
                return str(v)
            return f"{int(round(n)):,}"
        except Exception:
            return str(v)

    num_cols = [c for c in left_T.columns if ("ë§¤ì¶œì•¡" in c) or ("ìŠ¹ê°ìˆ˜" in c)]
    for c in num_cols:
        left_T[c] = left_T[c].apply(_fmt_commas)



# ==== ì‹¤ì ê¸°ê°„(ì „ì¹˜) í‘œì— 'ì™¸ë¶€ìš”ì¸'ê³¼ 'íœ´ì¼' ì»¬ëŸ¼ ì¶”ê°€ ====
if not left_T.empty and not left_tbl.empty:
    # ì™¸ë¶€ìš”ì¸ ë¬¸ìì—´ ("ì´ë²¤íŠ¸ N")
    ext_values = build_event_strings(pd.DatetimeIndex(left_tbl["date"]), external_factors_df)
    # íœ´ì¼ ë¼ë²¨ (6ì ì´ë‚´)
    left_holiday_labels, _ = build_holiday_labels(pd.DatetimeIndex(left_tbl["date"]), holidays_df, max_len=6)

    # ì „ì¹˜ í…Œì´ë¸” ì¸ë±ìŠ¤ì™€ ë§ì¶°ì„œ ì»¬ëŸ¼ ê¸¸ì´ ì •ë ¬
    def _append_aligned_column(T: pd.DataFrame, dates: pd.Series, values: list, col_name: str):
        date_labels = list(fmt_date_ko(pd.Series(dates)))
        mapping = {lbl: val for lbl, val in zip(date_labels, values)}
        aligned = []
        for idx in T.index:
            aligned.append("" if str(idx) == "í•©ê³„" else mapping.get(idx, ""))
        T[col_name] = aligned
        return T

    left_T = _append_aligned_column(left_T, left_tbl["date"], ext_values, "ì™¸ë¶€ìš”ì¸")
    left_T = _append_aligned_column(left_T, left_tbl["date"], left_holiday_labels, "íœ´ì¼")

# ==== ì˜ˆì¸¡ê¸°ê°„(ì „ì¹˜) í‘œ: ë§¨ ì˜¤ë¥¸ìª½ì— 'íœ´ì¼'ë§Œ ì¶”ê°€ ====
if not right_T.empty and not right_tbl.empty:
    # ë„ìš°ë¯¸: ì „ì¹˜ í…Œì´ë¸” ì¸ë±ìŠ¤(í•©ê³„ í¬í•¨)ì— ë§ì¶° ì•ˆì „í•˜ê²Œ ì»¬ëŸ¼ ì¶”ê°€
    def _append_aligned_column(T: pd.DataFrame, dates: pd.Series, values: list, col_name: str):
        date_labels = list(fmt_date_ko(pd.Series(dates)))
        mapping = {lbl: val for lbl, val in zip(date_labels, values)}
        aligned = []
        for idx in T.index:
            aligned.append("" if str(idx) == "í•©ê³„" else mapping.get(idx, ""))
        T[col_name] = aligned
        return T

    # 1) í˜¹ì‹œ ì´ì „ ì½”ë“œë¡œ 'íœ´ë¬´'ê°€ ìˆì—ˆë‹¤ë©´ ì œê±°
    if "íœ´ë¬´" in right_T.columns:
        right_T = right_T.drop(columns=["íœ´ë¬´"])

    # 2) íœ´ì¼ ë¼ë²¨ ìƒì„±
    right_holiday_labels, _ = build_holiday_labels(pd.DatetimeIndex(right_tbl["date"]), holidays_df, max_len=6)

    # 3) ì´ë¯¸ 'íœ´ì¼'ì´ ìˆìœ¼ë©´ ë§¨ ë’¤ë¡œ ì´ë™(popâ†’ì¬í• ë‹¹), ì—†ìœ¼ë©´ ìƒˆë¡œ ì¶”ê°€
    if "íœ´ì¼" in right_T.columns:
        _col = right_T.pop("íœ´ì¼")
        right_T["íœ´ì¼"] = _col
    else:
        right_T = _append_aligned_column(right_T, right_tbl["date"], right_holiday_labels, "íœ´ì¼")



# ---- (ë„ìš°ë¯¸) ì „ì¹˜ í…Œì´ë¸”ì˜ ì¸ë±ìŠ¤ì— ë§ì¶° ì•ˆì „í•˜ê²Œ ì»¬ëŸ¼ ì¶”ê°€ ----
def _append_aligned_column(T: pd.DataFrame, dates: pd.Series, values: list, col_name: str):
    """
    T: ì „ì¹˜ëœ í…Œì´ë¸” (index = ["í•©ê³„", fmt_date_ko(...), ...])
    dates: ì›ë³¸ ë‚ ì§œ Series (ì˜ˆ: left_tbl["date"] or right_tbl["date"])
    values: ë‚ ì§œ ê°œìˆ˜ë§Œí¼ì˜ ê°’ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ì™¸ë¶€ìš”ì¸/íœ´ì¼ ë¼ë²¨ë“¤)
    col_name: ì¶”ê°€í•  ì»¬ëŸ¼ëª…
    """
    if T is None or T.empty:
        return T
    # ì „ì¹˜ í…Œì´ë¸”ì˜ ì¸ë±ìŠ¤(ì¼ì ë¼ë²¨)ì— ë§ì¶° ë§¤í•‘
    date_labels = list(fmt_date_ko(pd.Series(dates)))
    mapping = {lbl: val for lbl, val in zip(date_labels, values)}

    aligned = []
    for idx in T.index:
        if str(idx) == "í•©ê³„":
            aligned.append("")  # í•©ê³„ í–‰ì—ëŠ” ë¹ˆê°’
        else:
            aligned.append(mapping.get(idx, ""))  # í•´ë‹¹ ì¼ì ì—†ìœ¼ë©´ ë¹ˆê°’

# ---- ìŠ¤íƒ€ì¼ ----
def _style_weekend_rows(df: pd.DataFrame) -> pd.io.formats.style.Styler:
    blue_text = "#1e90ff"; red_text = "#ef4444"
    sty = df.style.set_properties(**{"text-align":"center"}) \
                  .set_table_styles([{"selector":"th","props":"text-align:center;"}])
    if "í•©ê³„" in df.index:
        sty = sty.set_properties(subset=(["í•©ê³„"], df.columns),
                                 **{"font-weight":"bold","background-color": SUM_BG})
    for idx in df.index:
        if isinstance(idx, str) and "(í† )" in idx:
            sty = sty.set_properties(subset=([idx], df.columns), **{"color": blue_text})
        if isinstance(idx, str) and "(ì¼)" in idx:
            sty = sty.set_properties(subset=([idx], df.columns), **{"color": red_text})
    return sty

# ---- ì¶œë ¥ ----
c1, c2 = st.columns(2)
with c1:
    st.markdown("**ì‹¤ì  ê¸°ê°„ (ì „ì¹˜)**")
    if left_T.empty:
        st.info("ì‹¤ì  ê¸°ê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # 1) ì¸ë±ìŠ¤('ì¼ì')ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ êº¼ë‚´ê¸°
        left_T.index.name = "ì¼ì"
        left_edit = left_T.reset_index()

        # 2) 'ì™¸ë¶€ìš”ì¸' ì˜¤ë¥¸ìª½ì— ì²´í¬ë°•ìŠ¤ ì»¬ëŸ¼ ì¶”ê°€ (ì—†ìœ¼ë©´ ë§¨ ëì— ì¶”ê°€)
        insert_pos = left_edit.columns.get_loc("ì™¸ë¶€ìš”ì¸") + 1 if "ì™¸ë¶€ìš”ì¸" in left_edit.columns else len(left_edit.columns)
        if "ì„ íƒ" not in left_edit.columns:
            left_edit.insert(insert_pos, "ì„ íƒ", False)

        # 3) í•©ê³„ í–‰ì€ ì²´í¬í•´ë„ ë¬´ì‹œí•˜ë„ë¡ í‘œì‹œ(ì‹œê°ì ìœ¼ë¡œëŠ” ì²´í¬ ê°€ëŠ¥í•˜ì§€ë§Œ ì²˜ë¦¬ì—ì„œ ì œì™¸)
        #    â€» st.data_editorëŠ” í–‰ ë‹¨ìœ„ ë¹„í™œì„±í™”ê°€ ì—†ì–´, í›„ì²˜ë¦¬ì—ì„œ ì œì™¸í•©ë‹ˆë‹¤.
        #    í•„ìš”í•˜ë©´ 'í•©ê³„' í–‰ì— ì•ˆë‚´ í…ìŠ¤íŠ¸ë¥¼ ë§ë¶™ì—¬ë„ ë©ë‹ˆë‹¤.

        # 4) ì—ë””í„° ë Œë” (ì²´í¬ë°•ìŠ¤ í¬í•¨)
        edited_left = st.data_editor(
            left_edit,
            hide_index=True,
            use_container_width=True,
            height=min(520, 140 + 28 * max(3, len(left_edit))),
            column_config={
                "ì„ íƒ": st.column_config.CheckboxColumn(
                    "ì„ íƒ",
                    help="í•´ë‹¹ ì¼ìì˜ ì´ë²¤íŠ¸ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.",
                    default=False,
                ),
            },
            disabled=["ì¼ì"],  # ë‚ ì§œëŠ” ìˆ˜ì • ëª» í•˜ë„ë¡
        )

        # 5) ì„ íƒ ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥ (í•©ê³„ í–‰ ì œì™¸)
        selected_mask = (edited_left.get("ì„ íƒ") == True) & (edited_left.get("ì¼ì") != "í•©ê³„")
        st.session_state["selected_event_dates_from_matrix"] = edited_left.loc[selected_mask, "ì¼ì"].tolist()





        # 6) ì„ íƒ ìš”ì•½ í‘œì‹œ (ì›í•˜ë©´ ì´ ê°’ì„ í†µí•© ìƒì„¸ ì„¹ì…˜ê³¼ ì—°ë™ ê°€ëŠ¥)
        if st.session_state["selected_event_dates_from_matrix"]:
            st.caption("âœ… ì„ íƒëœ ì¼ì: " + ", ".join(st.session_state["selected_event_dates_from_matrix"]))
        else:
            st.caption("ì„ íƒëœ ì¼ìê°€ ì—†ìŠµë‹ˆë‹¤.")

# ==== ì²´í¬ëœ ë‚ ì§œì˜ ì´ë²¤íŠ¸ ì„¸ë¡œ ë‚˜ì—´ ====
def _label_to_date(lbl: str) -> pd.Timestamp | None:
    # "YYYY-MM-DD (ìš”ì¼)" í˜•ì‹ì—ì„œ ì• 10ìë¦¬ë§Œ íŒŒì‹±
    try:
        s = str(lbl).strip()
        iso = s[:10]  # "YYYY-MM-DD"
        dt = pd.to_datetime(iso, errors="coerce")
        return None if pd.isna(dt) else dt.normalize()
    except Exception:
        return None

# 1) ì„ íƒëœ 'ì¼ì' ë¼ë²¨ â†’ ë‚ ì§œë¡œ ë³€í™˜
_selected_labels = st.session_state.get("selected_event_dates_from_matrix", []) or []
_selected_dates = [d for d in (_label_to_date(x) for x in _selected_labels) if d is not None]
_selected_dates = sorted(set(_selected_dates))

# 2) í†µí•© ì´ë²¤íŠ¸ ë§µ í™•ë³´ (ì„¸ì…˜ì— ì—†ìœ¼ë©´ ì¦‰ì„ ìƒì„±)
integrated_map = st.session_state.get("integrated_event_map", None)

def _build_integrated_map_for_range(s: pd.Timestamp, e: pd.Timestamp) -> dict:
    if s is None or e is None or s > e:
        return {}
    visible_left = pd.date_range(s, e, freq="D")

    # ì½˜ì„œíŠ¸
    concert_counts_df = load_concert_counts_df()
    concert_info_df   = load_concert_info_df()
    concert_map = build_concert_map_by_date(visible_left, concert_counts_df, concert_info_df)

    # ë°•ëŒíšŒ
    expo_counts_df = load_expo_counts_df()
    coex_info_df   = load_expo_info_df("coex_events_rows.csv",   "Coex")
    kintex_info_df = load_expo_info_df("kintex_events_rows.csv", "Kintex")
    bexco_info_df  = load_expo_info_df("bexco_events_rows.csv",  "Bexco")
    coex_map   = build_event_titles_by_date(visible_left, expo_counts_df, coex_info_df,   "coex_events_count")
    kintex_map = build_event_titles_by_date(visible_left, expo_counts_df, kintex_info_df, "kintex_events_count")
    bexco_map  = build_event_titles_by_date(visible_left, expo_counts_df, bexco_info_df,  "bexco_events_count")

    # ìŠ¤í¬ì¸ 
    sports_counts_df = load_sports_counts_df()
    baseball_df = load_baseball_schedule_df()
    kleague_df  = load_kleague_schedule_df()
    baseball_map = build_single_day_titles_by_date(visible_left, sports_counts_df, baseball_df, "games_baseball", info_date_col="date")
    kleague_map  = build_single_day_titles_by_date(visible_left, sports_counts_df, kleague_df,  "games_soccer",   info_date_col="date")

    # í•©ì¹˜ê¸°
    out = {}
    for d in visible_left:
        d0 = d.normalize()
        items = []
        items += concert_map.get(d0, [])
        items += coex_map.get(d0, [])
        items += kintex_map.get(d0, [])
        items += bexco_map.get(d0, [])
        items += baseball_map.get(d0, [])
        items += kleague_map.get(d0, [])
        if items:
            out[d0] = items
    return out

if integrated_map is None:
    # ì‹¤ì  ê¸°ê°„(l_s~l_e)ì„ ê¸°ì¤€ìœ¼ë¡œ ì¦‰ì„ ìƒì„± (ìƒë‹¨ì—ì„œ ì´ë¯¸ l_s, l_e ê³„ì‚°ë¨)
    integrated_map = _build_integrated_map_for_range(l_s, l_e)
    st.session_state["integrated_event_map"] = integrated_map  # ìºì‹œ

# 3) í™”ë©´ ì¶œë ¥
st.markdown("#### ğŸ” ì„ íƒí•œ ì¼ì ì´ë²¤íŠ¸")
if not _selected_dates:
    st.info("ì²´í¬í•œ ë‚ ì§œê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    for d in _selected_dates:
        # ë‚ ì§œ ë¼ë²¨ (ìš”ì¼ í¬í•¨)
        pretty = fmt_date_ko(pd.Series([d])).iloc[0]
        events = integrated_map.get(d, [])
        st.write(f"**{pretty}**")
        if events:
            for t in events:
                st.markdown(f"- {t}")
        else:
            st.markdown("- (í‘œì‹œí•  ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤)")


with c2:
    st.markdown("**ì˜ˆì¸¡ ê¸°ê°„ (ì „ì¹˜)**")
    if right_T.empty:
        st.info("ì˜ˆì¸¡ ê¸°ê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        right_T.index.name = "ì¼ì"
        st.dataframe(_style_weekend_rows(right_T), use_container_width=True,
                     height=min(520, 140 + 28 * max(3, len(right_T))))



# ===================== 9ì›” ì˜ˆì¸¡ ì •í™•ë„ (ì‹¤ì  vs ì˜ˆì¸¡) =====================
st.markdown("#### ğŸ¯ ì˜ˆì¸¡ ì •í™•ë„ (ì‹¤ì  vs ì˜ˆì¸¡)")


SEP_START = pd.to_datetime("2025-09-01")
SEP_END   = pd.to_datetime("2025-09-30")

@st.cache_data(show_spinner=False)
def load_actual_sep_df() -> pd.DataFrame:
    """
    actual_sep_rows.csvì—ì„œ 2025-09-01 ~ 2025-09-30 ì¼ìë³„ ì‹¤ì ì„ ë¡œë“œ.
    - ë‹¤ì–‘í•œ ì»¬ëŸ¼ëª…/í˜•ì‹ì„ ê²¬ê³ í•˜ê²Œ ì²˜ë¦¬
    - ë‚ ì§œ ì»¬ëŸ¼ ìë™ ì¶”ë¡ : travel_date / date / ì¼ì / ë‚ ì§œ / (ì—°,ì›”,ì¼ ì¡°í•©)
    - ìˆ«ì ì „ì²˜ë¦¬: ì‰¼í‘œ/ê³µë°±/í†µí™”ê¸°í˜¸ ì œê±° í›„ numeric ìºìŠ¤íŒ…
    - ë™ì¼ ì¼ì ì¤‘ë³µ í•©ì‚°
    """
    SEP_START = pd.to_datetime("2025-09-01")
    SEP_END   = pd.to_datetime("2025-09-30")

    try:
        raw = load_df_from_repo_csv("actual_sep_rows.csv").copy()
    except FileNotFoundError:
        st.warning("'actual_sep_rows.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (9ì›” ì •í™•ë„ í‘œ ìƒëµ)")
        return pd.DataFrame(columns=["date","passengers","sales_amount"])

    if raw.empty:
        st.warning("actual_sep_rows.csvê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return pd.DataFrame(columns=["date","passengers","sales_amount"])

    # 1) ì»¬ëŸ¼ëª… í‘œì¤€í™”
    df = raw.copy()
    df.columns = [str(c).strip().lower() for c in df.columns]

    # 2) ë‚ ì§œ ì»¬ëŸ¼ ì¶”ë¡ 
    date_col_candidates = [
        "travel_date","date","ì¼ì","ë‚ ì§œ","ts","dt"
    ]
    ymd_candidates = [
        ("year","month","day"),
        ("yyyy","mm","dd"),
        ("y","m","d"),
        ("s_y","s_m","s_d"),  # ì¢…ì¢… ì“°ë˜ í¬ë§· ëŒ€ì‘
    ]
    date_series = None
    for c in date_col_candidates:
        if c in df.columns:
            date_series = pd.to_datetime(df[c], errors="coerce")
            break
    if date_series is None:
        # ì—°/ì›”/ì¼ ë¶„ë¦¬í˜• ì¡°í•© ì‹œë„
        for y,m,d in ymd_candidates:
            if y in df.columns and m in df.columns and d in df.columns:
                yv = pd.to_numeric(df[y], errors="coerce")
                mv = pd.to_numeric(df[m], errors="coerce")
                dv = pd.to_numeric(df[d], errors="coerce")
                date_series = pd.to_datetime(
                    yv.astype("Int64").astype(str).str.zfill(4) + "-" +
                    mv.astype("Int64").astype(str).str.zfill(2) + "-" +
                    dv.astype("Int64").astype(str).str.zfill(2),
                    errors="coerce"
                )
                break
    if date_series is None:
        st.warning("actual_sep_rows.csvì—ì„œ ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (travel_date/date/ì¼ì/ë‚ ì§œ ë˜ëŠ” ì—°Â·ì›”Â·ì¼ ì¡°í•© í•„ìš”)")
        return pd.DataFrame(columns=["date","passengers","sales_amount"])

    df["date"] = pd.to_datetime(date_series, errors="coerce").dt.normalize()

    # 3) ìŠ¹ê°/ë§¤ì¶œ ì»¬ëŸ¼ ì¶”ë¡ 
    def _pick_col(candidates: list[str]) -> str | None:
        for c in candidates:
            if c in df.columns:
                return c
        # ë¶€ë¶„ ì¼ì¹˜(ì˜ˆ: 'sales amount', 'ë§¤ì¶œ(ì›)')
        for c in df.columns:
            for key in candidates:
                if key in c:
                    return c
        return None

    pax_col = _pick_col(["passengers","pax","ridership","ìŠ¹ê°","ìŠ¹ê°ìˆ˜"])
    sales_col = _pick_col(["sales_amount","sales","revenue","amount","ë§¤ì¶œ","ë§¤ì¶œì•¡"])

    if pax_col is None and sales_col is None:
        st.warning("actual_sep_rows.csvì—ì„œ ìŠ¹ê°/ë§¤ì¶œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(columns=["date","passengers","sales_amount"])

    # 4) ìˆ«ì ì „ì²˜ë¦¬ ìœ í‹¸
    def to_numeric_clean(s):
        if s is None:
            return pd.Series(dtype="float64")
        return (
            pd.Series(s, dtype="object")
            .astype(str)
            .str.replace(r"[,\sâ‚©ì›$â‚©]", "", regex=True)
            .replace({"": np.nan, "nan": np.nan})
            .pipe(pd.to_numeric, errors="coerce")
        )

    if pax_col is not None:
        df["passengers"] = to_numeric_clean(df[pax_col])
    else:
        df["passengers"] = np.nan

    if sales_col is not None:
        df["sales_amount"] = to_numeric_clean(df[sales_col])
    else:
        df["sales_amount"] = np.nan

    # 5) ìœ íš¨ ë¡œìš°ë§Œ ë‚¨ê¸°ê³  ì¼ìë³„ í•©ì‚°
    df = df.dropna(subset=["date"])
    if df[["passengers","sales_amount"]].isna().all(axis=None):
        st.warning("actual_sep_rows.csvì˜ ìŠ¹ê°/ë§¤ì¶œ ê°’ì´ ëª¨ë‘ ê²°ì¸¡ì…ë‹ˆë‹¤.")
        return pd.DataFrame(columns=["date","passengers","sales_amount"])

    daily = (df.groupby("date", as_index=False)[["passengers","sales_amount"]]
               .sum(min_count=1)  # ì „ë¶€ NaNì´ë©´ NaN ìœ ì§€
               .sort_values("date"))

    # 6) 9ì›” ê¸°ê°„ í•„í„°
    daily = daily[(daily["date"] >= SEP_START) & (daily["date"] <= SEP_END)]

    if daily.empty:
        st.info("actual_sep_rows.csvì—ì„œ 2025-09 ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        # ë””ë²„ê·¸ ë„ì›€ë§
        with st.expander("ğŸ” ë””ë²„ê·¸: ì›ë³¸ ë‚ ì§œ ë¶„í¬ ë³´ê¸°"):
            try:
                tmp = pd.to_datetime(raw.iloc[:,0], errors="coerce")
                st.write("ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ ë‚ ì§œë¡œ ìºìŠ¤íŒ…í•œ ì˜ˆì‹œ(ë¬´ê´€í•  ìˆ˜ ìˆìŒ):", tmp.min(), "~", tmp.max())
            except Exception:
                st.write("ì›ë³¸ ë¯¸ë¦¬ë³´ê¸°:", raw.head())
        return pd.DataFrame(columns=["date","passengers","sales_amount"])

    return daily[["date","passengers","sales_amount"]]



def _safe_pct_err(forecast, actual):
    if pd.isna(actual) or actual == 0:
        return np.nan
    return (forecast - actual) / actual * 100.0


# --- ë°ì´í„° ì¤€ë¹„: 9ì›” ì‹¤ì  / ì˜ˆì¸¡
actual_sep = load_actual_sep_df()

# forecast_pass.csv (ìŠ¹ê°) + forecast_sales.csv (ë§¤ì¶œ)ì—ì„œ 9ì›”ë§Œ
fcst_pass_sep = forecast_df_all[(forecast_df_all["date"] >= SEP_START) & (forecast_df_all["date"] <= SEP_END)][["date","passengers"]].rename(columns={"passengers":"f_passengers"})
fcst_sales_sep = forecast_sales_all[(forecast_sales_all["date"] >= SEP_START) & (forecast_sales_all["date"] <= SEP_END)][["date","pred_sales_amount"]].rename(columns={"pred_sales_amount":"f_sales_amount"})

fcst_sep = pd.merge(fcst_pass_sep, fcst_sales_sep, on="date", how="outer").sort_values("date")

# --- ì˜ˆì¸¡ ê¸°ê°„ ì—°ë™ (r_s, r_e)
sel_start = max(r_s, SEP_START)
sel_end   = min(r_e, SEP_END)
cmp = pd.merge(fcst_sep, actual_sep, on="date", how="outer")
cmp = cmp[(cmp["date"] >= sel_start) & (cmp["date"] <= sel_end)].sort_values("date").reset_index(drop=True)

cmp["a_passengers"]   = pd.to_numeric(cmp.get("passengers"), errors="coerce")
cmp["a_sales_amount"] = pd.to_numeric(cmp.get("sales_amount"), errors="coerce")
cmp["f_passengers"]   = pd.to_numeric(cmp.get("f_passengers"), errors="coerce")
cmp["f_sales_amount"] = pd.to_numeric(cmp.get("f_sales_amount"), errors="coerce")

cmp["pax_err_pct"]   = [ _safe_pct_err(fp, ap) for fp, ap in zip(cmp["f_passengers"], cmp["a_passengers"]) ]
cmp["sales_err_pct"] = [ _safe_pct_err(fs, as_) for fs, as_ in zip(cmp["f_sales_amount"], cmp["a_sales_amount"]) ]

# --- í‘œ ìƒì„± (ë‹¨ìœ„: ë§¤ì¶œ=ë°±ë§Œì›, ìŠ¹ê°=ì²œëª…)
disp = pd.DataFrame({
    "ì¼ì": fmt_date_ko(cmp["date"].dt.tz_localize(None)) if "date" in cmp.columns else pd.Series(dtype=str),
    "ì‹¤ì |ë§¤ì¶œì•¡(ë°±ë§Œì›)":  (cmp["a_sales_amount"] / 1_000_000).round(0).astype("Int64"),
    "ì˜ˆì¸¡|ë§¤ì¶œì•¡(ë°±ë§Œì›)":  (cmp["f_sales_amount"] / 1_000_000).round(0).astype("Int64"),
    "ì˜¤ì°¨ìœ¨|ë§¤ì¶œì•¡(%)":   cmp["sales_err_pct"].map(lambda x: f"{x:.1f}" if not pd.isna(x) else ""),
    "ì‹¤ì |ìŠ¹ê°ìˆ˜(ì²œëª…)":    (cmp["a_passengers"]  / 1_000).round(0).astype("Int64"),
    "ì˜ˆì¸¡|ìŠ¹ê°ìˆ˜(ì²œëª…)":    (cmp["f_passengers"]  / 1_000).round(0).astype("Int64"),
    "ì˜¤ì°¨ìœ¨|ìŠ¹ê°ìˆ˜(%)":   cmp["pax_err_pct"].map(lambda x: f"{x:.1f}" if not pd.isna(x) else ""),
})

# --- í•©ê³„í–‰ (MAPE)
def _mape_pct(f, a):
    s = [abs((fv - av)/av)*100.0 for fv, av in zip(f, a) if (not pd.isna(av) and av!=0 and not pd.isna(fv))]
    return np.nan if len(s)==0 else float(np.mean(s))

sum_a_pax   = cmp["a_passengers"].sum(skipna=True)
sum_f_pax   = cmp["f_passengers"].sum(skipna=True)
sum_a_sales = cmp["a_sales_amount"].sum(skipna=True)
sum_f_sales = cmp["f_sales_amount"].sum(skipna=True)
mape_pax   = _mape_pct(cmp["f_passengers"], cmp["a_passengers"])
mape_sales = _mape_pct(cmp["f_sales_amount"], cmp["a_sales_amount"])

sum_row = pd.DataFrame([{
    "ì¼ì": "í•©ê³„",
    "ì‹¤ì |ë§¤ì¶œì•¡(ë°±ë§Œì›)": int(round(sum_a_sales/1_000_000)) if not pd.isna(sum_a_sales) else pd.NA,
    "ì˜ˆì¸¡|ë§¤ì¶œì•¡(ë°±ë§Œì›)": int(round(sum_f_sales/1_000_000)) if not pd.isna(sum_f_sales) else pd.NA,
    "ì˜¤ì°¨ìœ¨|ë§¤ì¶œì•¡(%)":    round(mape_sales, 1) if not pd.isna(mape_sales) else pd.NA,
    "ì‹¤ì |ìŠ¹ê°ìˆ˜(ì²œëª…)":   int(round(sum_a_pax/1_000)) if not pd.isna(sum_a_pax) else pd.NA,
    "ì˜ˆì¸¡|ìŠ¹ê°ìˆ˜(ì²œëª…)":   int(round(sum_f_pax/1_000)) if not pd.isna(sum_f_pax) else pd.NA,
    "ì˜¤ì°¨ìœ¨|ìŠ¹ê°ìˆ˜(%)":    round(mape_pax, 1) if not pd.isna(mape_pax) else pd.NA,
}])

disp_out = pd.concat([sum_row, disp], ignore_index=True)

# --- ì£¼ë§ì€ ê¸€ì”¨ìƒ‰ìœ¼ë¡œë§Œ í‘œì‹œ
def _weekday_textcolor_only_df(_df: pd.DataFrame) -> pd.DataFrame:
    blue_text = "#1e90ff"
    red_text  = "#ef4444"
    styles = pd.DataFrame("", index=_df.index, columns=_df.columns)
    for i in _df.index[1:]:
        d = str(_df.at[i, "ì¼ì"]) if "ì¼ì" in _df.columns else ""
        if "(í† )" in d:
            styles.loc[i, :] = [f"color:{blue_text};"] * styles.shape[1]
        if "(ì¼)" in d:
            styles.loc[i, :] = [f"color:{red_text};"] * styles.shape[1]
    if 0 in styles.index:
        styles.loc[0, :] = [f"font-weight:bold; background-color:{SUM_BG};"] * styles.shape[1]
    return styles

# --- í‘œì‹œ
st.dataframe(
    disp_out.style
        .set_properties(**{"text-align":"center"})
        .set_table_styles([{"selector":"th","props":"text-align:center;"}])
        .apply(_weekday_textcolor_only_df, axis=None),
    use_container_width=True,
    height=min(520, 120 + 28 * (len(disp_out)+1))
)



